unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.1,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 6,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 6
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918829
Load word2vec
>> Epoch 0
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 10.265640 rc_loss 8.653811 kl_loss 0.746717 bow_loss 0.865113 
unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.2,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 6,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 6
0.20 elbo_t 10.734160 rc_loss 8.589451 kl_loss 1.287022 bow_loss 0.857688 
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918851
Load word2vec
>> Epoch 0
Learning rate 0.001000
unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.3,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 6,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 6
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918862
Load word2vec
>> Epoch 0
Learning rate 0.001000
0.30 elbo_t 10.336770 rc_loss 8.511819 kl_loss 0.977731 bow_loss 0.847221 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 11.130753 rc_loss 8.653811 kl_loss 0.746717 bow_loss 1.730226 
unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.4,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 7,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 7
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918875
Load word2vec
>> Epoch 0
Learning rate 0.001000
unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.5,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 7,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 7
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 11.995867 rc_loss 8.653811 kl_loss 0.746717 bow_loss 2.595339 
0.40 elbo_t 10.074615 rc_loss 8.430681 kl_loss 0.809650 bow_loss 0.834285 
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918885
Load word2vec
>> Epoch 0
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 12.860980 rc_loss 8.653811 kl_loss 0.746717 bow_loss 3.460451 
0.20 elbo_t 11.591774 rc_loss 8.590362 kl_loss 1.287371 bow_loss 1.714041 
unable to import 'smart_open.gcs', disabling that module
Namespace(ckpt_dir='', ckpt_name='', forward_only=False, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.6,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.json',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.json',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 7,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 7
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918893
Load word2vec
>> Epoch 0
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 13.726091 rc_loss 8.653811 kl_loss 0.746717 bow_loss 4.325564 
0.20 elbo_t 12.448640 rc_loss 8.591338 kl_loss 1.287461 bow_loss 2.569840 
0.50 elbo_t 9.857750 rc_loss 8.344749 kl_loss 0.693596 bow_loss 0.819405 
0.20 elbo_t 13.305441 rc_loss 8.592273 kl_loss 1.287752 bow_loss 3.425416 
0.30 elbo_t 11.183009 rc_loss 8.513659 kl_loss 0.977956 bow_loss 1.691396 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 14.591205 rc_loss 8.653811 kl_loss 0.746717 bow_loss 5.190678 
0.30 elbo_t 12.027965 rc_loss 8.515594 kl_loss 0.978039 bow_loss 2.534332 
0.60 elbo_t 9.656181 rc_loss 8.251041 kl_loss 0.603224 bow_loss 0.801915 
0.20 elbo_t 14.161835 rc_loss 8.593192 kl_loss 1.287884 bow_loss 4.280758 
0.30 elbo_t 12.872379 rc_loss 8.517396 kl_loss 0.978276 bow_loss 3.376707 
0.40 elbo_t 10.907019 rc_loss 8.433712 kl_loss 0.809836 bow_loss 1.663471 
0.20 elbo_t 15.018095 rc_loss 8.594018 kl_loss 1.288123 bow_loss 5.135953 
0.40 elbo_t 11.737352 rc_loss 8.436794 kl_loss 0.809918 bow_loss 2.490640 
0.70 elbo_t 9.455634 rc_loss 8.141896 kl_loss 0.531830 bow_loss 0.781908 
0.30 elbo_t 13.716022 rc_loss 8.519128 kl_loss 0.978325 bow_loss 4.218569 
0.40 elbo_t 12.566580 rc_loss 8.439615 kl_loss 0.810114 bow_loss 3.316851 
0.50 elbo_t 10.674532 rc_loss 8.349373 kl_loss 0.693759 bow_loss 1.631400 
0.30 elbo_t 14.559235 rc_loss 8.520681 kl_loss 0.978456 bow_loss 5.060098 
0.50 elbo_t 11.488356 rc_loss 8.353902 kl_loss 0.693846 bow_loss 2.440607 
0.80 elbo_t 9.263332 rc_loss 8.020453 kl_loss 0.482019 bow_loss 0.760860 
0.50 elbo_t 12.300522 rc_loss 8.357984 kl_loss 0.694018 bow_loss 3.248520 
0.40 elbo_t 13.394651 rc_loss 8.442269 kl_loss 0.810158 bow_loss 4.142224 
0.60 elbo_t 10.454960 rc_loss 8.257616 kl_loss 0.603356 bow_loss 1.593988 
0.40 elbo_t 14.222053 rc_loss 8.444617 kl_loss 0.810294 bow_loss 4.967141 
0.90 elbo_t 9.070724 rc_loss 7.883701 kl_loss 0.447881 bow_loss 0.739142 
0.60 elbo_t 11.249939 rc_loss 8.263809 kl_loss 0.603425 bow_loss 2.382705 
0.50 elbo_t 13.111117 rc_loss 8.361728 kl_loss 0.694061 bow_loss 4.055327 
0.60 elbo_t 12.042507 rc_loss 8.269251 kl_loss 0.603567 bow_loss 3.169690 
0.70 elbo_t 10.234993 rc_loss 8.151036 kl_loss 0.531932 bow_loss 1.552025 
0.50 elbo_t 13.920611 rc_loss 8.364953 kl_loss 0.694172 bow_loss 4.861486 
0.70 elbo_t 11.009618 rc_loss 8.159292 kl_loss 0.531963 bow_loss 2.318362 
1.00 elbo_t 8.876250 rc_loss 7.742357 kl_loss 0.414672 bow_loss 0.719221 
Epoch Done elbo_t 8.876250 rc_loss 7.742357 kl_loss 0.414672 bow_loss 0.719221 step time 17.4322
Best valid loss before this validation: inf
0.70 elbo_t 11.780956 rc_loss 8.166354 kl_loss 0.532046 bow_loss 3.082556 
0.60 elbo_t 12.833071 rc_loss 8.274160 kl_loss 0.603592 bow_loss 3.955318 
0.80 elbo_t 10.023438 rc_loss 8.032536 kl_loss 0.482092 bow_loss 1.508810 
0.60 elbo_t 13.622112 rc_loss 8.278358 kl_loss 0.603664 bow_loss 4.740090 
0.80 elbo_t 10.777982 rc_loss 8.043115 kl_loss 0.482096 bow_loss 2.252771 
0.70 elbo_t 12.549894 rc_loss 8.172613 kl_loss 0.532032 bow_loss 3.845249 
0.80 elbo_t 11.528393 rc_loss 8.051997 kl_loss 0.482139 bow_loss 2.994258 
0.90 elbo_t 9.812185 rc_loss 7.899031 kl_loss 0.447930 bow_loss 1.465224 
0.70 elbo_t 13.316919 rc_loss 8.177958 kl_loss 0.532064 bow_loss 4.606897 
Test begins with 3 batches with 16 left over samples
Traceback (most recent call last):
  File "train_interpret.py", line 5, in <module>
    ckpt_dir, ckpt_name = train_linear_vrnn.main(["--train"])
  File "/home/liangqiu/Workpace/TSAN-Dialogues/train_linear_vrnn.py", line 260, in main
    valid_loss = valid(model, valid_loader, writer, epoch)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/train_linear_vrnn.py", line 98, in valid
    loss = model(*batch)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/models/linear_vrnn.py", line 185, in forward
    input_query=input_query)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/models/linear_vae_cell.py", line 349, in forward
    bow_logits2=bow_logits2)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/utils/loss.py", line 81, in BPR_BOW_loss
    tile_bow_logits2, labels_2) * label_mask_2.float()
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2009, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1317, in log_softmax
    ret = input.log_softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 6; 23.62 GiB total capacity; 9.75 GiB already allocated; 38.44 MiB free; 93.35 MiB cached)
0.90 elbo_t 10.547338 rc_loss 7.912160 kl_loss 0.447925 bow_loss 2.187253 
0.90 elbo_t 11.277555 rc_loss 7.923067 kl_loss 0.447953 bow_loss 2.906536 
0.80 elbo_t 12.275990 rc_loss 8.059715 kl_loss 0.482106 bow_loss 3.734167 
1.00 elbo_t 9.601245 rc_loss 7.760700 kl_loss 0.414723 bow_loss 1.425823 
Epoch Done elbo_t 9.601245 rc_loss 7.760700 kl_loss 0.414723 bow_loss 1.425823 step time 19.7737
Best valid loss before this validation: inf
0.80 elbo_t 13.021332 rc_loss 8.066328 kl_loss 0.482132 bow_loss 4.472872 
1.00 elbo_t 10.319125 rc_loss 7.776254 kl_loss 0.414732 bow_loss 2.128139 
Epoch Done elbo_t 10.319125 rc_loss 7.776254 kl_loss 0.414732 bow_loss 2.128139 step time 19.6281
Best valid loss before this validation: inf
1.00 elbo_t 11.031252 rc_loss 7.789101 kl_loss 0.414773 bow_loss 2.827379 
Epoch Done elbo_t 11.031252 rc_loss 7.789101 kl_loss 0.414773 bow_loss 2.827379 step time 19.1361
Best valid loss before this validation: inf
0.90 elbo_t 12.004447 rc_loss 7.932367 kl_loss 0.447920 bow_loss 3.624160 
0.90 elbo_t 12.728752 rc_loss 7.940379 kl_loss 0.447953 bow_loss 4.340420 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 7.194397 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 1
Learning rate 0.001000
1.00 elbo_t 11.739478 rc_loss 7.799944 kl_loss 0.414753 bow_loss 3.524781 
Epoch Done elbo_t 11.739478 rc_loss 7.799944 kl_loss 0.414753 bow_loss 3.524781 step time 20.2806
Best valid loss before this validation: inf
Test begins with 3 batches with 16 left over samples
Valid elbo_t 7.733356 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 1
Learning rate 0.001000
1.00 elbo_t 12.444695 rc_loss 7.809312 kl_loss 0.414798 bow_loss 4.220584 
Epoch Done elbo_t 12.444695 rc_loss 7.809312 kl_loss 0.414798 bow_loss 4.220584 step time 20.7054
Best valid loss before this validation: inf
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 7.195910 rc_loss 6.129642 kl_loss 0.045250 bow_loss 1.021019 
Test begins with 3 batches with 16 left over samples
Traceback (most recent call last):
  File "train_interpret.py", line 5, in <module>
    ckpt_dir, ckpt_name = train_linear_vrnn.main(["--train"])
  File "/home/liangqiu/Workpace/TSAN-Dialogues/train_linear_vrnn.py", line 260, in main
    valid_loss = valid(model, valid_loader, writer, epoch)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/train_linear_vrnn.py", line 98, in valid
    loss = model(*batch)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/models/linear_vrnn.py", line 185, in forward
    input_query=input_query)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/models/linear_vae_cell.py", line 349, in forward
    bow_logits2=bow_logits2)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/utils/loss.py", line 81, in BPR_BOW_loss
    tile_bow_logits2, labels_2) * label_mask_2.float()
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/module.py", line 541, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/modules/loss.py", line 916, in forward
    ignore_index=self.ignore_index, reduction=self.reduction)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 2009, in cross_entropy
    return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
  File "/home/liangqiu/Workpace/TSAN-Dialogues/venv/lib/python3.6/site-packages/torch/nn/functional.py", line 1317, in log_softmax
    ret = input.log_softmax(dim)
RuntimeError: CUDA out of memory. Tried to allocate 60.00 MiB (GPU 7; 23.62 GiB total capacity; 9.75 GiB already allocated; 24.44 MiB free; 93.35 MiB cached)
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 7.736356 rc_loss 6.173986 kl_loss 0.045442 bow_loss 1.516927 
0.20 elbo_t 6.956039 rc_loss 5.930356 kl_loss 0.038504 bow_loss 0.987180 
0.20 elbo_t 7.477733 rc_loss 5.975189 kl_loss 0.038647 bow_loss 1.463897 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 8.765228 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 1
Learning rate 0.001000
0.30 elbo_t 6.714976 rc_loss 5.715678 kl_loss 0.042972 bow_loss 0.956326 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 9.266694 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 1
Learning rate 0.001000
0.30 elbo_t 7.217071 rc_loss 5.758699 kl_loss 0.043077 bow_loss 1.415295 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 8.772738 rc_loss 6.239402 kl_loss 0.045755 bow_loss 2.487582 
0.40 elbo_t 6.512704 rc_loss 5.531525 kl_loss 0.050520 bow_loss 0.930659 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 9.276383 rc_loss 6.265077 kl_loss 0.045840 bow_loss 2.965467 
0.40 elbo_t 7.000584 rc_loss 5.574578 kl_loss 0.050761 bow_loss 1.375244 
0.20 elbo_t 8.475084 rc_loss 6.042222 kl_loss 0.038881 bow_loss 2.393983 
0.50 elbo_t 6.311672 rc_loss 5.351394 kl_loss 0.053996 bow_loss 0.906281 
0.20 elbo_t 8.958918 rc_loss 6.068906 kl_loss 0.038956 bow_loss 2.851057 
0.50 elbo_t 6.785693 rc_loss 5.393422 kl_loss 0.054315 bow_loss 1.337955 
0.30 elbo_t 8.175628 rc_loss 5.824274 kl_loss 0.043222 bow_loss 2.308132 
0.60 elbo_t 6.106053 rc_loss 5.172135 kl_loss 0.052291 bow_loss 0.881627 
0.30 elbo_t 8.640851 rc_loss 5.851226 kl_loss 0.043305 bow_loss 2.746320 
0.60 elbo_t 6.567176 rc_loss 5.213092 kl_loss 0.052591 bow_loss 1.301494 
0.40 elbo_t 7.929866 rc_loss 5.640149 kl_loss 0.051039 bow_loss 2.238679 
0.70 elbo_t 5.923851 rc_loss 5.013865 kl_loss 0.047746 bow_loss 0.862239 
0.40 elbo_t 8.380381 rc_loss 5.666922 kl_loss 0.051165 bow_loss 2.662295 
0.70 elbo_t 6.374744 rc_loss 5.052813 kl_loss 0.047986 bow_loss 1.273945 
0.50 elbo_t 7.689743 rc_loss 5.458089 kl_loss 0.054678 bow_loss 2.176976 
0.80 elbo_t 5.762108 rc_loss 4.870852 kl_loss 0.044512 bow_loss 0.846745 
0.50 elbo_t 8.128685 rc_loss 5.484607 kl_loss 0.054821 bow_loss 2.589257 
0.80 elbo_t 6.204903 rc_loss 4.907537 kl_loss 0.044807 bow_loss 1.252559 
0.60 elbo_t 7.449285 rc_loss 5.276324 kl_loss 0.052928 bow_loss 2.120033 
0.90 elbo_t 5.621515 rc_loss 4.743319 kl_loss 0.043940 bow_loss 0.834258 
0.60 elbo_t 7.878976 rc_loss 5.302638 kl_loss 0.053054 bow_loss 2.523284 
0.90 elbo_t 6.057703 rc_loss 4.777557 kl_loss 0.044445 bow_loss 1.235702 
0.70 elbo_t 7.240900 rc_loss 5.113136 kl_loss 0.048268 bow_loss 2.079495 
1.00 elbo_t 5.493574 rc_loss 4.624862 kl_loss 0.044882 bow_loss 0.823829 
Epoch Done elbo_t 5.493574 rc_loss 4.624862 kl_loss 0.044882 bow_loss 0.823829 step time 15.4387
Best valid loss before this validation: 7.194397
0.70 elbo_t 7.664163 rc_loss 5.138499 kl_loss 0.048372 bow_loss 2.477292 
1.00 elbo_t 5.924039 rc_loss 4.656850 kl_loss 0.045504 bow_loss 1.221685 
Epoch Done elbo_t 5.924039 rc_loss 4.656850 kl_loss 0.045504 bow_loss 1.221685 step time 15.5545
Best valid loss before this validation: 7.733356
0.80 elbo_t 7.059358 rc_loss 4.965219 kl_loss 0.045157 bow_loss 2.048981 
0.80 elbo_t 7.477674 rc_loss 4.989536 kl_loss 0.045292 bow_loss 2.442847 
0.90 elbo_t 6.902403 rc_loss 4.832128 kl_loss 0.045012 bow_loss 2.025263 
0.90 elbo_t 7.316668 rc_loss 4.855242 kl_loss 0.045241 bow_loss 2.416185 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.209822 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 2
Learning rate 0.001000
1.00 elbo_t 6.760394 rc_loss 4.708623 kl_loss 0.046174 bow_loss 2.005596 
Epoch Done elbo_t 6.760394 rc_loss 4.708623 kl_loss 0.046174 bow_loss 2.005596 step time 15.5616
Best valid loss before this validation: 8.765228
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.581480 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 2
Learning rate 0.001000
1.00 elbo_t 7.171127 rc_loss 4.730606 kl_loss 0.046441 bow_loss 2.394080 
Epoch Done elbo_t 7.171127 rc_loss 4.730606 kl_loss 0.046441 bow_loss 2.394080 step time 15.5149
Best valid loss before this validation: 9.266694
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.239127 rc_loss 3.461889 kl_loss 0.047098 bow_loss 0.730140 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.611360 rc_loss 3.468654 kl_loss 0.046485 bow_loss 1.096221 
0.20 elbo_t 4.123318 rc_loss 3.364925 kl_loss 0.038523 bow_loss 0.719870 
0.20 elbo_t 4.488912 rc_loss 3.370471 kl_loss 0.037472 bow_loss 1.080969 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 5.332548 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 2
Learning rate 0.001000
0.30 elbo_t 4.085986 rc_loss 3.335599 kl_loss 0.028896 bow_loss 0.721491 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 5.706368 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 2
Learning rate 0.001000
0.30 elbo_t 4.451541 rc_loss 3.339978 kl_loss 0.028167 bow_loss 1.083397 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 5.368138 rc_loss 3.491932 kl_loss 0.045793 bow_loss 1.830413 
0.40 elbo_t 4.049849 rc_loss 3.302520 kl_loss 0.024710 bow_loss 0.722618 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 5.744337 rc_loss 3.501385 kl_loss 0.045396 bow_loss 2.197556 
0.40 elbo_t 4.415501 rc_loss 3.306034 kl_loss 0.024511 bow_loss 1.084955 
0.20 elbo_t 5.233732 rc_loss 3.392869 kl_loss 0.036445 bow_loss 1.804419 
0.50 elbo_t 4.019830 rc_loss 3.272955 kl_loss 0.023673 bow_loss 0.723202 
0.20 elbo_t 5.603829 rc_loss 3.401811 kl_loss 0.035977 bow_loss 2.166042 
0.50 elbo_t 4.384869 rc_loss 3.275479 kl_loss 0.023756 bow_loss 1.085634 
0.30 elbo_t 5.196801 rc_loss 3.361034 kl_loss 0.027526 bow_loss 1.808240 
0.60 elbo_t 3.980184 rc_loss 3.233677 kl_loss 0.024086 bow_loss 0.722421 
0.30 elbo_t 5.567479 rc_loss 3.369680 kl_loss 0.027253 bow_loss 2.170547 
0.60 elbo_t 4.344188 rc_loss 3.235526 kl_loss 0.024321 bow_loss 1.084341 
0.40 elbo_t 5.160931 rc_loss 3.326280 kl_loss 0.024400 bow_loss 1.810250 
0.70 elbo_t 3.952285 rc_loss 3.205493 kl_loss 0.024014 bow_loss 0.722777 
0.40 elbo_t 5.531846 rc_loss 3.334711 kl_loss 0.024348 bow_loss 2.172788 
0.70 elbo_t 4.315755 rc_loss 3.206658 kl_loss 0.024365 bow_loss 1.084731 
0.50 elbo_t 5.130100 rc_loss 3.295316 kl_loss 0.023912 bow_loss 1.810871 
0.80 elbo_t 3.921990 rc_loss 3.176021 kl_loss 0.023451 bow_loss 0.722519 
0.50 elbo_t 5.501062 rc_loss 3.303726 kl_loss 0.023967 bow_loss 2.173369 
0.80 elbo_t 4.284415 rc_loss 3.176588 kl_loss 0.023647 bow_loss 1.084181 
0.60 elbo_t 5.088495 rc_loss 3.255407 kl_loss 0.024652 bow_loss 1.808436 
0.90 elbo_t 3.892600 rc_loss 3.148023 kl_loss 0.021981 bow_loss 0.722595 
0.60 elbo_t 5.458993 rc_loss 3.263836 kl_loss 0.024804 bow_loss 2.170353 
0.90 elbo_t 4.254359 rc_loss 3.148165 kl_loss 0.022030 bow_loss 1.084163 
0.70 elbo_t 5.060329 rc_loss 3.226821 kl_loss 0.024773 bow_loss 1.808735 
1.00 elbo_t 3.864941 rc_loss 3.121893 kl_loss 0.020660 bow_loss 0.722389 
Epoch Done elbo_t 3.864941 rc_loss 3.121893 kl_loss 0.020660 bow_loss 0.722389 step time 15.3397
Best valid loss before this validation: 4.209822
0.70 elbo_t 5.430728 rc_loss 3.235234 kl_loss 0.024944 bow_loss 2.170552 
1.00 elbo_t 4.226415 rc_loss 3.121779 kl_loss 0.020876 bow_loss 1.083759 
Epoch Done elbo_t 4.226415 rc_loss 3.121779 kl_loss 0.020876 bow_loss 1.083759 step time 15.5865
Best valid loss before this validation: 4.581480
0.80 elbo_t 5.027966 rc_loss 3.196626 kl_loss 0.023842 bow_loss 1.807499 
0.80 elbo_t 5.397722 rc_loss 3.204901 kl_loss 0.023902 bow_loss 2.168920 
0.90 elbo_t 4.997825 rc_loss 3.168488 kl_loss 0.022169 bow_loss 1.807168 
0.90 elbo_t 5.367506 rc_loss 3.176884 kl_loss 0.022243 bow_loss 2.168379 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.579740 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 3
Learning rate 0.001000
1.00 elbo_t 4.970023 rc_loss 3.142502 kl_loss 0.021242 bow_loss 1.806279 
Epoch Done elbo_t 4.970023 rc_loss 3.142502 kl_loss 0.021242 bow_loss 1.806279 step time 15.6462
Best valid loss before this validation: 5.332548
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.937725 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 3
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.475635 rc_loss 2.757499 kl_loss 0.013839 bow_loss 0.704297 
1.00 elbo_t 5.339715 rc_loss 3.151024 kl_loss 0.021434 bow_loss 2.167256 
Epoch Done elbo_t 5.339715 rc_loss 3.151024 kl_loss 0.021434 bow_loss 2.167256 step time 15.5771
Best valid loss before this validation: 5.706368
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.827461 rc_loss 2.756014 kl_loss 0.015541 bow_loss 1.055906 
0.20 elbo_t 3.523235 rc_loss 2.796450 kl_loss 0.014666 bow_loss 0.712119 
0.20 elbo_t 3.877942 rc_loss 2.794918 kl_loss 0.015553 bow_loss 1.067471 
0.30 elbo_t 3.516801 rc_loss 2.789244 kl_loss 0.014987 bow_loss 0.712571 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.680752 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 3
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 5.048767 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 3
Learning rate 0.001000
0.30 elbo_t 3.871548 rc_loss 2.787535 kl_loss 0.015914 bow_loss 1.068100 
0.40 elbo_t 3.512488 rc_loss 2.784967 kl_loss 0.014032 bow_loss 0.713490 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.555199 rc_loss 2.779310 kl_loss 0.016603 bow_loss 1.759286 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.915693 rc_loss 2.787775 kl_loss 0.016814 bow_loss 2.111104 
0.40 elbo_t 3.867805 rc_loss 2.783388 kl_loss 0.014826 bow_loss 1.069592 
0.50 elbo_t 3.505496 rc_loss 2.776677 kl_loss 0.013598 bow_loss 0.715221 
0.20 elbo_t 4.612773 rc_loss 2.817997 kl_loss 0.016300 bow_loss 1.778476 
0.20 elbo_t 4.976815 rc_loss 2.826168 kl_loss 0.016635 bow_loss 2.134013 
0.50 elbo_t 3.861398 rc_loss 2.775164 kl_loss 0.013952 bow_loss 1.072283 
0.60 elbo_t 3.491061 rc_loss 2.763471 kl_loss 0.012393 bow_loss 0.715196 
0.30 elbo_t 4.606941 rc_loss 2.810888 kl_loss 0.016926 bow_loss 1.779127 
0.30 elbo_t 4.971390 rc_loss 2.819328 kl_loss 0.017448 bow_loss 2.134614 
0.60 elbo_t 3.846935 rc_loss 2.762072 kl_loss 0.012544 bow_loss 1.072318 
0.70 elbo_t 3.478146 rc_loss 2.751570 kl_loss 0.011335 bow_loss 0.715241 
0.40 elbo_t 4.603687 rc_loss 2.806217 kl_loss 0.015563 bow_loss 1.781906 
0.40 elbo_t 4.968722 rc_loss 2.814818 kl_loss 0.015884 bow_loss 2.138020 
0.70 elbo_t 3.834401 rc_loss 2.750259 kl_loss 0.011642 bow_loss 1.072500 
0.80 elbo_t 3.466937 rc_loss 2.740414 kl_loss 0.011017 bow_loss 0.715506 
0.50 elbo_t 4.598446 rc_loss 2.797721 kl_loss 0.014220 bow_loss 1.786506 
0.50 elbo_t 4.964503 rc_loss 2.806595 kl_loss 0.014343 bow_loss 2.143565 
0.80 elbo_t 3.823578 rc_loss 2.739208 kl_loss 0.011383 bow_loss 1.072986 
0.90 elbo_t 3.449837 rc_loss 2.723929 kl_loss 0.010681 bow_loss 0.715228 
0.60 elbo_t 4.583710 rc_loss 2.784346 kl_loss 0.012765 bow_loss 1.786600 
0.60 elbo_t 4.950115 rc_loss 2.793518 kl_loss 0.012917 bow_loss 2.143681 
0.90 elbo_t 3.806494 rc_loss 2.722798 kl_loss 0.011108 bow_loss 1.072588 
1.00 elbo_t 3.439059 rc_loss 2.713124 kl_loss 0.010495 bow_loss 0.715440 
Epoch Done elbo_t 3.439059 rc_loss 2.713124 kl_loss 0.010495 bow_loss 0.715440 step time 15.4472
Best valid loss before this validation: 3.579740
0.70 elbo_t 4.570734 rc_loss 2.771801 kl_loss 0.012015 bow_loss 1.786919 
0.70 elbo_t 4.937403 rc_loss 2.781111 kl_loss 0.012219 bow_loss 2.144073 
1.00 elbo_t 3.795773 rc_loss 2.711900 kl_loss 0.010932 bow_loss 1.072941 
Epoch Done elbo_t 3.795773 rc_loss 2.711900 kl_loss 0.010932 bow_loss 1.072941 step time 15.5612
Best valid loss before this validation: 3.937725
0.80 elbo_t 4.560073 rc_loss 2.760448 kl_loss 0.011765 bow_loss 1.787860 
0.80 elbo_t 4.927122 rc_loss 2.769928 kl_loss 0.011960 bow_loss 2.145234 
0.90 elbo_t 4.542881 rc_loss 2.744114 kl_loss 0.011597 bow_loss 1.787170 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.285169 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 4
Learning rate 0.001000
0.90 elbo_t 4.910145 rc_loss 2.753869 kl_loss 0.011865 bow_loss 2.144411 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.640939 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 4
Learning rate 0.001000
1.00 elbo_t 4.532326 rc_loss 2.733072 kl_loss 0.011436 bow_loss 1.787818 
Epoch Done elbo_t 4.532326 rc_loss 2.733072 kl_loss 0.011436 bow_loss 1.787818 step time 15.8070
Best valid loss before this validation: 4.680752
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.300409 rc_loss 2.577405 kl_loss 0.008515 bow_loss 0.714488 
1.00 elbo_t 4.899770 rc_loss 2.742826 kl_loss 0.011714 bow_loss 2.145229 
Epoch Done elbo_t 4.899770 rc_loss 2.742826 kl_loss 0.011714 bow_loss 2.145229 step time 15.6532
Best valid loss before this validation: 5.048767
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.656584 rc_loss 2.576333 kl_loss 0.008397 bow_loss 1.071853 
0.20 elbo_t 3.292537 rc_loss 2.568996 kl_loss 0.008119 bow_loss 0.715423 
0.20 elbo_t 3.648906 rc_loss 2.567876 kl_loss 0.007926 bow_loss 1.073103 
0.30 elbo_t 3.273268 rc_loss 2.551784 kl_loss 0.007481 bow_loss 0.714002 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.376244 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 4
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.745017 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 4
Learning rate 0.001000
0.30 elbo_t 3.628305 rc_loss 2.550113 kl_loss 0.007312 bow_loss 1.070880 
0.40 elbo_t 3.253894 rc_loss 2.533668 kl_loss 0.006997 bow_loss 0.713229 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.390381 rc_loss 2.595432 kl_loss 0.008280 bow_loss 1.786669 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.758867 rc_loss 2.606449 kl_loss 0.008329 bow_loss 2.144090 
0.40 elbo_t 3.607936 rc_loss 2.531366 kl_loss 0.006804 bow_loss 1.069766 
0.50 elbo_t 3.245493 rc_loss 2.525334 kl_loss 0.006526 bow_loss 0.713633 
0.20 elbo_t 4.384026 rc_loss 2.587625 kl_loss 0.007790 bow_loss 1.788611 
0.20 elbo_t 4.752581 rc_loss 2.598314 kl_loss 0.007829 bow_loss 2.146438 
0.50 elbo_t 3.599546 rc_loss 2.522586 kl_loss 0.006580 bow_loss 1.070381 
0.60 elbo_t 3.233736 rc_loss 2.513507 kl_loss 0.006324 bow_loss 0.713905 
0.30 elbo_t 4.361077 rc_loss 2.569145 kl_loss 0.007101 bow_loss 1.784830 
0.30 elbo_t 4.728556 rc_loss 2.579658 kl_loss 0.007063 bow_loss 2.141834 
0.60 elbo_t 3.587913 rc_loss 2.510598 kl_loss 0.006511 bow_loss 1.070805 
0.70 elbo_t 3.215287 rc_loss 2.496166 kl_loss 0.006308 bow_loss 0.712812 
0.40 elbo_t 4.340032 rc_loss 2.550399 kl_loss 0.006621 bow_loss 1.783011 
0.40 elbo_t 4.707108 rc_loss 2.560818 kl_loss 0.006611 bow_loss 2.139679 
0.70 elbo_t 3.568797 rc_loss 2.493213 kl_loss 0.006456 bow_loss 1.069128 
0.80 elbo_t 3.203931 rc_loss 2.484675 kl_loss 0.006246 bow_loss 0.713010 
0.50 elbo_t 4.332325 rc_loss 2.541656 kl_loss 0.006652 bow_loss 1.784016 
0.50 elbo_t 4.699632 rc_loss 2.551988 kl_loss 0.006737 bow_loss 2.140908 
0.80 elbo_t 3.557481 rc_loss 2.481688 kl_loss 0.006363 bow_loss 1.069430 
0.90 elbo_t 3.180638 rc_loss 2.462963 kl_loss 0.006089 bow_loss 0.711586 
0.60 elbo_t 4.321259 rc_loss 2.529901 kl_loss 0.006622 bow_loss 1.784736 
0.60 elbo_t 4.688540 rc_loss 2.540094 kl_loss 0.006687 bow_loss 2.141758 
0.90 elbo_t 3.533552 rc_loss 2.460052 kl_loss 0.006206 bow_loss 1.067293 
1.00 elbo_t 3.168393 rc_loss 2.450509 kl_loss 0.006139 bow_loss 0.711745 
Epoch Done elbo_t 3.168393 rc_loss 2.450509 kl_loss 0.006139 bow_loss 0.711745 step time 15.3720
Best valid loss before this validation: 3.285169
0.70 elbo_t 4.300616 rc_loss 2.512139 kl_loss 0.006546 bow_loss 1.781930 
0.70 elbo_t 4.667229 rc_loss 2.522227 kl_loss 0.006618 bow_loss 2.138384 
1.00 elbo_t 3.521470 rc_loss 2.447656 kl_loss 0.006242 bow_loss 1.067572 
Epoch Done elbo_t 3.521470 rc_loss 2.447656 kl_loss 0.006242 bow_loss 1.067572 step time 15.5466
Best valid loss before this validation: 3.640939
0.80 elbo_t 4.289518 rc_loss 2.500597 kl_loss 0.006477 bow_loss 1.782444 
0.80 elbo_t 4.656079 rc_loss 2.510516 kl_loss 0.006569 bow_loss 2.138994 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.046723 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 5
Learning rate 0.001000
0.90 elbo_t 4.630051 rc_loss 2.488937 kl_loss 0.006370 bow_loss 2.134744 
0.90 elbo_t 4.264177 rc_loss 2.478973 kl_loss 0.006303 bow_loss 1.778902 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.400420 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 5
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.011509 rc_loss 2.301235 kl_loss 0.005886 bow_loss 0.704387 
1.00 elbo_t 4.617826 rc_loss 2.476216 kl_loss 0.006275 bow_loss 2.135335 
Epoch Done elbo_t 4.617826 rc_loss 2.476216 kl_loss 0.006275 bow_loss 2.135335 step time 15.5137
Best valid loss before this validation: 4.745017
1.00 elbo_t 4.252028 rc_loss 2.466392 kl_loss 0.006260 bow_loss 1.779376 
Epoch Done elbo_t 4.252028 rc_loss 2.466392 kl_loss 0.006260 bow_loss 1.779376 step time 15.8163
Best valid loss before this validation: 4.376244
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.360332 rc_loss 2.298808 kl_loss 0.005170 bow_loss 1.056355 
0.20 elbo_t 3.010283 rc_loss 2.298587 kl_loss 0.005097 bow_loss 0.706599 
0.20 elbo_t 3.360982 rc_loss 2.296400 kl_loss 0.004910 bow_loss 1.059673 
0.30 elbo_t 3.014202 rc_loss 2.299315 kl_loss 0.005131 bow_loss 0.709755 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.497252 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 5
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.131090 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 5
Learning rate 0.001000
0.30 elbo_t 3.367192 rc_loss 2.297496 kl_loss 0.005245 bow_loss 1.064451 
0.40 elbo_t 3.010043 rc_loss 2.294093 kl_loss 0.005445 bow_loss 0.710506 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.444121 rc_loss 2.326966 kl_loss 0.004524 bow_loss 2.112632 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.082491 rc_loss 2.317333 kl_loss 0.004655 bow_loss 1.760503 
0.40 elbo_t 3.363314 rc_loss 2.292067 kl_loss 0.005621 bow_loss 1.065626 
0.50 elbo_t 3.000592 rc_loss 2.284933 kl_loss 0.005395 bow_loss 0.710265 
0.20 elbo_t 4.447601 rc_loss 2.323350 kl_loss 0.005071 bow_loss 2.119180 
0.20 elbo_t 4.084977 rc_loss 2.314012 kl_loss 0.005007 bow_loss 1.765958 
0.50 elbo_t 3.353376 rc_loss 2.282606 kl_loss 0.005472 bow_loss 1.065298 
0.60 elbo_t 2.994231 rc_loss 2.278691 kl_loss 0.005025 bow_loss 0.710516 
0.30 elbo_t 4.458590 rc_loss 2.324337 kl_loss 0.005262 bow_loss 2.128991 
0.30 elbo_t 4.094238 rc_loss 2.314858 kl_loss 0.005302 bow_loss 1.774079 
0.60 elbo_t 3.347317 rc_loss 2.276451 kl_loss 0.005156 bow_loss 1.065710 
0.70 elbo_t 2.985312 rc_loss 2.269591 kl_loss 0.004801 bow_loss 0.710921 
0.40 elbo_t 4.455666 rc_loss 2.318892 kl_loss 0.005580 bow_loss 2.131194 
0.40 elbo_t 4.091196 rc_loss 2.309650 kl_loss 0.005635 bow_loss 1.775910 
0.70 elbo_t 3.338520 rc_loss 2.267234 kl_loss 0.004963 bow_loss 1.066323 
0.80 elbo_t 2.973493 rc_loss 2.257924 kl_loss 0.004738 bow_loss 0.710831 
0.50 elbo_t 4.444888 rc_loss 2.308952 kl_loss 0.005421 bow_loss 2.130515 
0.50 elbo_t 4.080597 rc_loss 2.299758 kl_loss 0.005476 bow_loss 1.775363 
0.80 elbo_t 3.326723 rc_loss 2.255655 kl_loss 0.004858 bow_loss 1.066211 
0.90 elbo_t 2.964472 rc_loss 2.248769 kl_loss 0.004571 bow_loss 0.711132 
0.60 elbo_t 4.439018 rc_loss 2.302342 kl_loss 0.005259 bow_loss 2.131416 
0.60 elbo_t 4.074543 rc_loss 2.293144 kl_loss 0.005263 bow_loss 1.776136 
0.90 elbo_t 3.317861 rc_loss 2.246505 kl_loss 0.004707 bow_loss 1.066650 
1.00 elbo_t 2.944657 rc_loss 2.230441 kl_loss 0.004395 bow_loss 0.709821 
Epoch Done elbo_t 2.944657 rc_loss 2.230441 kl_loss 0.004395 bow_loss 0.709821 step time 15.5220
Best valid loss before this validation: 3.046723
0.70 elbo_t 4.430545 rc_loss 2.292777 kl_loss 0.005012 bow_loss 2.132757 
0.70 elbo_t 4.065866 rc_loss 2.283624 kl_loss 0.005033 bow_loss 1.777210 
1.00 elbo_t 3.297459 rc_loss 2.228193 kl_loss 0.004539 bow_loss 1.064728 
Epoch Done elbo_t 3.297459 rc_loss 2.228193 kl_loss 0.004539 bow_loss 1.064728 step time 15.4714
Best valid loss before this validation: 3.400420
0.80 elbo_t 4.418513 rc_loss 2.281071 kl_loss 0.004876 bow_loss 2.132567 
0.80 elbo_t 4.054000 rc_loss 2.272045 kl_loss 0.004895 bow_loss 1.777059 
0.90 elbo_t 4.410097 rc_loss 2.271912 kl_loss 0.004751 bow_loss 2.133434 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.852401 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 6
Learning rate 0.001000
0.90 elbo_t 4.045487 rc_loss 2.262943 kl_loss 0.004774 bow_loss 1.777771 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.206117 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 6
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.846427 rc_loss 2.131053 kl_loss 0.003884 bow_loss 0.711491 
1.00 elbo_t 4.387805 rc_loss 2.253505 kl_loss 0.004640 bow_loss 2.129658 
Epoch Done elbo_t 4.387805 rc_loss 2.253505 kl_loss 0.004640 bow_loss 2.129658 step time 15.1797
Best valid loss before this validation: 4.497252
1.00 elbo_t 4.023871 rc_loss 2.244635 kl_loss 0.004639 bow_loss 1.774597 
Epoch Done elbo_t 4.023871 rc_loss 2.244635 kl_loss 0.004639 bow_loss 1.774597 step time 15.1917
Best valid loss before this validation: 4.131090
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.200859 rc_loss 2.129238 kl_loss 0.004459 bow_loss 1.067162 
0.20 elbo_t 2.825298 rc_loss 2.113853 kl_loss 0.004109 bow_loss 0.707336 
0.20 elbo_t 3.176665 rc_loss 2.111436 kl_loss 0.004418 bow_loss 1.060811 
0.30 elbo_t 2.822448 rc_loss 2.111429 kl_loss 0.003836 bow_loss 0.707183 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.298788 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 6
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.934820 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 6
Learning rate 0.001000
0.30 elbo_t 3.173592 rc_loss 2.109064 kl_loss 0.003967 bow_loss 1.060561 
0.40 elbo_t 2.821626 rc_loss 2.110281 kl_loss 0.003499 bow_loss 0.707847 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.290457 rc_loss 2.151178 kl_loss 0.004735 bow_loss 2.134544 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.927446 rc_loss 2.143984 kl_loss 0.004688 bow_loss 1.778775 
0.40 elbo_t 3.173144 rc_loss 2.107883 kl_loss 0.003667 bow_loss 1.061594 
0.50 elbo_t 2.811556 rc_loss 2.099819 kl_loss 0.003596 bow_loss 0.708141 
0.20 elbo_t 4.260690 rc_loss 2.134330 kl_loss 0.004712 bow_loss 2.121648 
0.20 elbo_t 3.899743 rc_loss 2.127273 kl_loss 0.004630 bow_loss 1.767840 
0.50 elbo_t 3.163139 rc_loss 2.097207 kl_loss 0.003859 bow_loss 1.062073 
0.60 elbo_t 2.805189 rc_loss 2.092776 kl_loss 0.003535 bow_loss 0.708878 
0.30 elbo_t 4.257303 rc_loss 2.131885 kl_loss 0.004196 bow_loss 2.121222 
0.30 elbo_t 3.896281 rc_loss 2.124683 kl_loss 0.004108 bow_loss 1.767490 
0.60 elbo_t 3.156973 rc_loss 2.090067 kl_loss 0.003720 bow_loss 1.063186 
0.70 elbo_t 2.800163 rc_loss 2.086946 kl_loss 0.003504 bow_loss 0.709714 
0.40 elbo_t 4.257606 rc_loss 2.130398 kl_loss 0.004003 bow_loss 2.123205 
0.40 elbo_t 3.896314 rc_loss 2.123242 kl_loss 0.003881 bow_loss 1.769192 
0.70 elbo_t 3.152434 rc_loss 2.084272 kl_loss 0.003683 bow_loss 1.064479 
0.80 elbo_t 2.794557 rc_loss 2.080793 kl_loss 0.003574 bow_loss 0.710190 
0.50 elbo_t 4.247953 rc_loss 2.119571 kl_loss 0.004260 bow_loss 2.124122 
0.50 elbo_t 3.886587 rc_loss 2.112484 kl_loss 0.004126 bow_loss 1.769977 
0.80 elbo_t 3.146852 rc_loss 2.077875 kl_loss 0.003799 bow_loss 1.065179 
0.90 elbo_t 2.774881 rc_loss 2.062703 kl_loss 0.003551 bow_loss 0.708627 
0.60 elbo_t 4.242670 rc_loss 2.112261 kl_loss 0.004072 bow_loss 2.126336 
0.60 elbo_t 3.881043 rc_loss 2.105296 kl_loss 0.003930 bow_loss 1.771818 
0.90 elbo_t 3.126345 rc_loss 2.059797 kl_loss 0.003759 bow_loss 1.062790 
1.00 elbo_t 2.766548 rc_loss 2.054444 kl_loss 0.003461 bow_loss 0.708643 
Epoch Done elbo_t 2.766548 rc_loss 2.054444 kl_loss 0.003461 bow_loss 0.708643 step time 15.5329
Best valid loss before this validation: 2.852401
0.70 elbo_t 4.239638 rc_loss 2.106600 kl_loss 0.004091 bow_loss 2.128947 
0.70 elbo_t 3.877588 rc_loss 2.099658 kl_loss 0.003921 bow_loss 1.774009 
1.00 elbo_t 3.118096 rc_loss 2.051624 kl_loss 0.003673 bow_loss 1.062798 
Epoch Done elbo_t 3.118096 rc_loss 2.051624 kl_loss 0.003673 bow_loss 1.062798 step time 15.5416
Best valid loss before this validation: 3.206117
0.80 elbo_t 4.234701 rc_loss 2.100112 kl_loss 0.004216 bow_loss 2.130373 
0.80 elbo_t 3.872498 rc_loss 2.093242 kl_loss 0.004068 bow_loss 1.775187 
0.90 elbo_t 4.211829 rc_loss 2.082101 kl_loss 0.004169 bow_loss 2.125558 
0.90 elbo_t 3.850359 rc_loss 2.075189 kl_loss 0.004015 bow_loss 1.771155 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.697428 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 7
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.050186 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 7
Learning rate 0.001000
1.00 elbo_t 4.203521 rc_loss 2.073859 kl_loss 0.004093 bow_loss 2.125570 
Epoch Done elbo_t 4.203521 rc_loss 2.073859 kl_loss 0.004093 bow_loss 2.125570 step time 15.4493
Best valid loss before this validation: 4.298788
1.00 elbo_t 3.842056 rc_loss 2.066972 kl_loss 0.003935 bow_loss 1.771148 
Epoch Done elbo_t 3.842056 rc_loss 2.066972 kl_loss 0.003935 bow_loss 1.771148 step time 15.3640
Best valid loss before this validation: 3.934820
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.674689 rc_loss 1.965048 kl_loss 0.003689 bow_loss 0.705952 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.023775 rc_loss 1.961055 kl_loss 0.003844 bow_loss 1.058877 
0.20 elbo_t 2.623581 rc_loss 1.919072 kl_loss 0.003782 bow_loss 0.700727 
0.20 elbo_t 2.970761 rc_loss 1.915882 kl_loss 0.003865 bow_loss 1.051014 
0.30 elbo_t 2.637503 rc_loss 1.930128 kl_loss 0.003363 bow_loss 0.704012 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.138975 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 7
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.775908 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 7
Learning rate 0.001000
0.30 elbo_t 2.986388 rc_loss 1.926970 kl_loss 0.003390 bow_loss 1.056027 
0.40 elbo_t 2.639436 rc_loss 1.930158 kl_loss 0.003087 bow_loss 0.706191 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 4.103622 rc_loss 1.982068 kl_loss 0.004617 bow_loss 2.116936 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.743379 rc_loss 1.974628 kl_loss 0.004461 bow_loss 1.764290 
0.40 elbo_t 2.989394 rc_loss 1.927009 kl_loss 0.003133 bow_loss 1.059251 
0.50 elbo_t 2.635031 rc_loss 1.926424 kl_loss 0.002995 bow_loss 0.705612 
0.20 elbo_t 4.044273 rc_loss 1.938350 kl_loss 0.004414 bow_loss 2.101509 
0.20 elbo_t 3.686305 rc_loss 1.930684 kl_loss 0.004281 bow_loss 1.751339 
0.50 elbo_t 2.984613 rc_loss 1.923181 kl_loss 0.003084 bow_loss 1.058348 
0.60 elbo_t 2.635185 rc_loss 1.925075 kl_loss 0.003236 bow_loss 0.706873 
0.30 elbo_t 3.705167 rc_loss 1.941855 kl_loss 0.003672 bow_loss 1.759639 
0.30 elbo_t 4.064485 rc_loss 1.949204 kl_loss 0.003806 bow_loss 2.111475 
0.60 elbo_t 2.985617 rc_loss 1.922045 kl_loss 0.003311 bow_loss 1.060262 
0.70 elbo_t 2.635856 rc_loss 1.925296 kl_loss 0.003235 bow_loss 0.707324 
0.40 elbo_t 3.709969 rc_loss 1.941684 kl_loss 0.003404 bow_loss 1.764881 
0.40 elbo_t 4.069860 rc_loss 1.948572 kl_loss 0.003560 bow_loss 2.117729 
0.70 elbo_t 2.986508 rc_loss 1.922257 kl_loss 0.003291 bow_loss 1.060960 
0.80 elbo_t 2.633155 rc_loss 1.922242 kl_loss 0.003196 bow_loss 0.707717 
0.50 elbo_t 3.704541 rc_loss 1.937819 kl_loss 0.003378 bow_loss 1.763344 
0.50 elbo_t 4.064181 rc_loss 1.944706 kl_loss 0.003526 bow_loss 2.115950 
0.80 elbo_t 2.983618 rc_loss 1.918846 kl_loss 0.003255 bow_loss 1.061517 
0.90 elbo_t 2.629946 rc_loss 1.919052 kl_loss 0.003180 bow_loss 0.707714 
0.60 elbo_t 3.706722 rc_loss 1.936566 kl_loss 0.003513 bow_loss 1.766643 
0.60 elbo_t 4.066940 rc_loss 1.943362 kl_loss 0.003608 bow_loss 2.119970 
0.90 elbo_t 2.980343 rc_loss 1.915565 kl_loss 0.003306 bow_loss 1.061473 
1.00 elbo_t 2.622252 rc_loss 1.911248 kl_loss 0.003237 bow_loss 0.707766 
Epoch Done elbo_t 2.622252 rc_loss 1.911248 kl_loss 0.003237 bow_loss 0.707766 step time 15.5788
Best valid loss before this validation: 2.697428
0.70 elbo_t 4.068013 rc_loss 1.943159 kl_loss 0.003507 bow_loss 2.121347 
0.70 elbo_t 3.707734 rc_loss 1.936484 kl_loss 0.003430 bow_loss 1.767820 
1.00 elbo_t 2.972603 rc_loss 1.907697 kl_loss 0.003379 bow_loss 1.061526 
Epoch Done elbo_t 2.972603 rc_loss 1.907697 kl_loss 0.003379 bow_loss 1.061526 step time 15.5214
Best valid loss before this validation: 3.050186
0.80 elbo_t 4.065807 rc_loss 1.939824 kl_loss 0.003485 bow_loss 2.122498 
0.80 elbo_t 3.705465 rc_loss 1.933292 kl_loss 0.003400 bow_loss 1.768773 
0.90 elbo_t 4.062031 rc_loss 1.936140 kl_loss 0.003568 bow_loss 2.122323 
0.90 elbo_t 3.701886 rc_loss 1.929770 kl_loss 0.003487 bow_loss 1.768629 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.571894 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 8
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.922874 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 8
Learning rate 0.001000
1.00 elbo_t 4.054012 rc_loss 1.928065 kl_loss 0.003571 bow_loss 2.122375 
Epoch Done elbo_t 4.054012 rc_loss 1.928065 kl_loss 0.003571 bow_loss 2.122375 step time 15.4827
Best valid loss before this validation: 4.138975
1.00 elbo_t 3.693953 rc_loss 1.921762 kl_loss 0.003523 bow_loss 1.768669 
Epoch Done elbo_t 3.693953 rc_loss 1.921762 kl_loss 0.003523 bow_loss 1.768669 step time 15.3831
Best valid loss before this validation: 3.775908
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.537566 rc_loss 1.825949 kl_loss 0.003626 bow_loss 0.707991 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.888206 rc_loss 1.822913 kl_loss 0.003472 bow_loss 1.061821 
0.20 elbo_t 2.550549 rc_loss 1.840424 kl_loss 0.003014 bow_loss 0.707111 
0.20 elbo_t 2.900035 rc_loss 1.836385 kl_loss 0.003203 bow_loss 1.060447 
0.30 elbo_t 2.538614 rc_loss 1.830632 kl_loss 0.002855 bow_loss 0.705127 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 4.005013 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 8
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.644407 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 8
Learning rate 0.001000
0.30 elbo_t 2.887009 rc_loss 1.826386 kl_loss 0.003146 bow_loss 1.057478 
0.40 elbo_t 2.539381 rc_loss 1.829152 kl_loss 0.003122 bow_loss 0.707107 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.967874 rc_loss 1.841624 kl_loss 0.003242 bow_loss 2.123007 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.608112 rc_loss 1.836322 kl_loss 0.003215 bow_loss 1.768575 
0.40 elbo_t 2.888823 rc_loss 1.824920 kl_loss 0.003420 bow_loss 1.060483 
0.50 elbo_t 2.533404 rc_loss 1.822389 kl_loss 0.003070 bow_loss 0.707945 
0.20 elbo_t 3.976995 rc_loss 1.853510 kl_loss 0.003529 bow_loss 2.119955 
0.20 elbo_t 3.617816 rc_loss 1.848138 kl_loss 0.003400 bow_loss 1.766279 
0.50 elbo_t 2.883063 rc_loss 1.817991 kl_loss 0.003318 bow_loss 1.061753 
0.60 elbo_t 2.531973 rc_loss 1.820590 kl_loss 0.003039 bow_loss 0.708344 
0.30 elbo_t 3.961599 rc_loss 1.844178 kl_loss 0.003405 bow_loss 2.114017 
0.30 elbo_t 3.603353 rc_loss 1.838674 kl_loss 0.003357 bow_loss 1.761322 
0.60 elbo_t 2.881797 rc_loss 1.816202 kl_loss 0.003277 bow_loss 1.062317 
0.70 elbo_t 2.530408 rc_loss 1.819150 kl_loss 0.002959 bow_loss 0.708299 
0.40 elbo_t 3.966738 rc_loss 1.843242 kl_loss 0.003502 bow_loss 2.119993 
0.40 elbo_t 3.607730 rc_loss 1.837866 kl_loss 0.003521 bow_loss 1.766343 
0.70 elbo_t 2.880411 rc_loss 1.814898 kl_loss 0.003224 bow_loss 1.062289 
0.80 elbo_t 2.511167 rc_loss 1.801455 kl_loss 0.002947 bow_loss 0.706765 
0.50 elbo_t 3.961854 rc_loss 1.836124 kl_loss 0.003420 bow_loss 2.122310 
0.50 elbo_t 3.602478 rc_loss 1.830689 kl_loss 0.003421 bow_loss 1.768368 
0.80 elbo_t 2.860443 rc_loss 1.797268 kl_loss 0.003187 bow_loss 1.059988 
0.90 elbo_t 2.507615 rc_loss 1.797474 kl_loss 0.003017 bow_loss 0.707123 
0.60 elbo_t 3.601572 rc_loss 1.828848 kl_loss 0.003440 bow_loss 1.769283 
0.60 elbo_t 3.961341 rc_loss 1.834422 kl_loss 0.003473 bow_loss 2.123446 
0.90 elbo_t 2.856821 rc_loss 1.793100 kl_loss 0.003211 bow_loss 1.060510 
1.00 elbo_t 2.502545 rc_loss 1.792586 kl_loss 0.002945 bow_loss 0.707015 
Epoch Done elbo_t 2.502545 rc_loss 1.792586 kl_loss 0.002945 bow_loss 0.707015 step time 15.4889
Best valid loss before this validation: 2.571894
0.70 elbo_t 3.599961 rc_loss 1.827237 kl_loss 0.003410 bow_loss 1.769314 
0.70 elbo_t 3.959497 rc_loss 1.832647 kl_loss 0.003436 bow_loss 2.123415 
1.00 elbo_t 2.851547 rc_loss 1.788054 kl_loss 0.003137 bow_loss 1.060356 
Epoch Done elbo_t 2.851547 rc_loss 1.788054 kl_loss 0.003137 bow_loss 1.060356 step time 15.5823
Best valid loss before this validation: 2.922874
0.80 elbo_t 3.578742 rc_loss 1.809932 kl_loss 0.003345 bow_loss 1.765465 
0.80 elbo_t 3.937483 rc_loss 1.815300 kl_loss 0.003364 bow_loss 2.118819 
0.90 elbo_t 3.575228 rc_loss 1.805628 kl_loss 0.003352 bow_loss 1.766249 
0.90 elbo_t 3.934129 rc_loss 1.811036 kl_loss 0.003384 bow_loss 2.119709 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.466925 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 9
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.817040 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 9
Learning rate 0.001000
1.00 elbo_t 3.569586 rc_loss 1.800282 kl_loss 0.003318 bow_loss 1.765986 
Epoch Done elbo_t 3.569586 rc_loss 1.800282 kl_loss 0.003318 bow_loss 1.765986 step time 15.2841
1.00 elbo_t 3.928524 rc_loss 1.805682 kl_loss 0.003373 bow_loss 2.119468 
Epoch Done elbo_t 3.928524 rc_loss 1.805682 kl_loss 0.003373 bow_loss 2.119468 step time 15.3661
Best valid loss before this validation: 3.644407
Best valid loss before this validation: 4.005013
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.451797 rc_loss 1.740870 kl_loss 0.002546 bow_loss 0.708380 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.801085 rc_loss 1.736168 kl_loss 0.002758 bow_loss 1.062158 
0.20 elbo_t 2.428663 rc_loss 1.718808 kl_loss 0.002945 bow_loss 0.706911 
0.20 elbo_t 2.777724 rc_loss 1.714579 kl_loss 0.003120 bow_loss 1.060025 
0.30 elbo_t 2.395270 rc_loss 1.689729 kl_loss 0.002972 bow_loss 0.702569 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.536552 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 9
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.894571 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 9
Learning rate 0.001000
0.30 elbo_t 2.742155 rc_loss 1.685625 kl_loss 0.003054 bow_loss 1.053477 
0.40 elbo_t 2.399320 rc_loss 1.691995 kl_loss 0.003109 bow_loss 0.704216 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.520421 rc_loss 1.749104 kl_loss 0.002873 bow_loss 1.768444 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.877856 rc_loss 1.753151 kl_loss 0.002851 bow_loss 2.121854 
0.40 elbo_t 2.746685 rc_loss 1.687536 kl_loss 0.003202 bow_loss 1.055947 
0.50 elbo_t 2.397894 rc_loss 1.691185 kl_loss 0.003191 bow_loss 0.703518 
0.20 elbo_t 3.494997 rc_loss 1.726543 kl_loss 0.003246 bow_loss 1.765208 
0.20 elbo_t 3.852313 rc_loss 1.730883 kl_loss 0.003330 bow_loss 2.118101 
0.50 elbo_t 2.744893 rc_loss 1.686734 kl_loss 0.003291 bow_loss 1.054867 
0.60 elbo_t 2.404088 rc_loss 1.697060 kl_loss 0.003059 bow_loss 0.703968 
0.30 elbo_t 3.456088 rc_loss 1.698223 kl_loss 0.003170 bow_loss 1.754695 
0.30 elbo_t 3.811639 rc_loss 1.702917 kl_loss 0.003294 bow_loss 2.105429 
0.60 elbo_t 2.751265 rc_loss 1.692531 kl_loss 0.003127 bow_loss 1.055607 
0.40 elbo_t 3.461354 rc_loss 1.699367 kl_loss 0.003352 bow_loss 1.758635 
0.70 elbo_t 2.404594 rc_loss 1.696433 kl_loss 0.003035 bow_loss 0.705126 
0.40 elbo_t 3.817738 rc_loss 1.704093 kl_loss 0.003487 bow_loss 2.110157 
0.70 elbo_t 2.752666 rc_loss 1.692148 kl_loss 0.003125 bow_loss 1.057393 
0.50 elbo_t 3.458963 rc_loss 1.698732 kl_loss 0.003417 bow_loss 1.756814 
0.50 elbo_t 3.814993 rc_loss 1.703472 kl_loss 0.003497 bow_loss 2.108025 
0.80 elbo_t 2.401190 rc_loss 1.693204 kl_loss 0.003156 bow_loss 0.704829 
0.80 elbo_t 2.748765 rc_loss 1.688610 kl_loss 0.003208 bow_loss 1.056947 
0.60 elbo_t 3.465623 rc_loss 1.704298 kl_loss 0.003216 bow_loss 1.758109 
0.60 elbo_t 3.821878 rc_loss 1.708879 kl_loss 0.003297 bow_loss 2.109702 
0.90 elbo_t 2.400529 rc_loss 1.692535 kl_loss 0.003114 bow_loss 0.704880 
0.90 elbo_t 2.747983 rc_loss 1.687791 kl_loss 0.003158 bow_loss 1.057034 
0.70 elbo_t 3.468349 rc_loss 1.703950 kl_loss 0.003266 bow_loss 1.761133 
0.70 elbo_t 3.825091 rc_loss 1.708331 kl_loss 0.003392 bow_loss 2.113369 
1.00 elbo_t 2.400194 rc_loss 1.691614 kl_loss 0.003185 bow_loss 0.705394 
Epoch Done elbo_t 2.400194 rc_loss 1.691614 kl_loss 0.003185 bow_loss 0.705394 step time 15.5062
Best valid loss before this validation: 2.466925
1.00 elbo_t 2.747879 rc_loss 1.686847 kl_loss 0.003239 bow_loss 1.057793 
Epoch Done elbo_t 2.747879 rc_loss 1.686847 kl_loss 0.003239 bow_loss 1.057793 step time 15.5488
Best valid loss before this validation: 2.817040
0.80 elbo_t 3.463851 rc_loss 1.700167 kl_loss 0.003340 bow_loss 1.760344 
0.80 elbo_t 3.820516 rc_loss 1.704551 kl_loss 0.003468 bow_loss 2.112497 
0.90 elbo_t 3.819656 rc_loss 1.703629 kl_loss 0.003400 bow_loss 2.112627 
0.90 elbo_t 3.463032 rc_loss 1.699252 kl_loss 0.003278 bow_loss 1.760502 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.377063 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 10
Learning rate 0.001000
1.00 elbo_t 3.820423 rc_loss 1.702847 kl_loss 0.003445 bow_loss 2.114131 
Epoch Done elbo_t 3.820423 rc_loss 1.702847 kl_loss 0.003445 bow_loss 2.114131 step time 15.2564
Best valid loss before this validation: 3.894571
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.725270 
Get a smaller valid loss, update the best valid loss
Saving the model
1.00 elbo_t 3.463530 rc_loss 1.698430 kl_loss 0.003334 bow_loss 1.761765 
Epoch Done elbo_t 3.463530 rc_loss 1.698430 kl_loss 0.003334 bow_loss 1.761765 step time 15.3605
Best valid loss before this validation: 3.536552
>> Epoch 10
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.250734 rc_loss 1.554258 kl_loss 0.003431 bow_loss 0.693044 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.591022 rc_loss 1.548425 kl_loss 0.003482 bow_loss 1.039114 
0.20 elbo_t 2.304591 rc_loss 1.599899 kl_loss 0.003529 bow_loss 0.701162 
0.20 elbo_t 2.649798 rc_loss 1.595046 kl_loss 0.003531 bow_loss 1.051221 
0.30 elbo_t 2.308475 rc_loss 1.605049 kl_loss 0.003364 bow_loss 0.700063 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.799674 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 10
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.442281 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 10
Learning rate 0.001000
0.30 elbo_t 2.652613 rc_loss 1.599687 kl_loss 0.003461 bow_loss 1.049465 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.647297 rc_loss 1.565935 kl_loss 0.003530 bow_loss 2.077833 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.296213 rc_loss 1.561271 kl_loss 0.003463 bow_loss 1.731479 
0.40 elbo_t 2.311905 rc_loss 1.606405 kl_loss 0.003337 bow_loss 0.702163 
0.40 elbo_t 2.657181 rc_loss 1.601076 kl_loss 0.003492 bow_loss 1.052612 
0.20 elbo_t 3.718137 rc_loss 1.612177 kl_loss 0.003706 bow_loss 2.102255 
0.20 elbo_t 3.363396 rc_loss 1.608045 kl_loss 0.003601 bow_loss 1.751750 
0.50 elbo_t 2.311223 rc_loss 1.605526 kl_loss 0.003378 bow_loss 0.702318 
0.50 elbo_t 2.656343 rc_loss 1.599960 kl_loss 0.003488 bow_loss 1.052895 
0.30 elbo_t 3.718174 rc_loss 1.616563 kl_loss 0.003699 bow_loss 2.097912 
0.30 elbo_t 3.364522 rc_loss 1.612415 kl_loss 0.003581 bow_loss 1.748526 
0.60 elbo_t 2.313092 rc_loss 1.606688 kl_loss 0.003138 bow_loss 0.703266 
0.60 elbo_t 2.658366 rc_loss 1.600748 kl_loss 0.003249 bow_loss 1.054369 
0.40 elbo_t 3.724823 rc_loss 1.617319 kl_loss 0.003679 bow_loss 2.103825 
0.40 elbo_t 3.370438 rc_loss 1.613262 kl_loss 0.003590 bow_loss 1.753586 
0.70 elbo_t 2.317024 rc_loss 1.610328 kl_loss 0.002943 bow_loss 0.703753 
0.70 elbo_t 2.662581 rc_loss 1.604399 kl_loss 0.003066 bow_loss 1.055116 
0.50 elbo_t 3.723430 rc_loss 1.615530 kl_loss 0.003629 bow_loss 2.104272 
0.50 elbo_t 3.369312 rc_loss 1.611703 kl_loss 0.003559 bow_loss 1.754050 
0.80 elbo_t 2.312356 rc_loss 1.605428 kl_loss 0.002892 bow_loss 0.704037 
0.80 elbo_t 2.658046 rc_loss 1.599482 kl_loss 0.003036 bow_loss 1.055528 
0.60 elbo_t 3.727057 rc_loss 1.616362 kl_loss 0.003434 bow_loss 2.107261 
0.60 elbo_t 3.372451 rc_loss 1.612516 kl_loss 0.003350 bow_loss 1.756586 
0.90 elbo_t 2.312677 rc_loss 1.605356 kl_loss 0.002819 bow_loss 0.704501 
0.90 elbo_t 2.658553 rc_loss 1.599364 kl_loss 0.002942 bow_loss 1.056247 
0.70 elbo_t 3.731860 rc_loss 1.619711 kl_loss 0.003272 bow_loss 2.108877 
0.70 elbo_t 3.376906 rc_loss 1.615828 kl_loss 0.003183 bow_loss 1.757896 
1.00 elbo_t 2.312197 rc_loss 1.605002 kl_loss 0.002782 bow_loss 0.704413 
Epoch Done elbo_t 2.312197 rc_loss 1.605002 kl_loss 0.002782 bow_loss 0.704413 step time 15.6091
Best valid loss before this validation: 2.377063
1.00 elbo_t 2.657884 rc_loss 1.598843 kl_loss 0.002896 bow_loss 1.056145 
Epoch Done elbo_t 2.657884 rc_loss 1.598843 kl_loss 0.002896 bow_loss 1.056145 step time 15.5782
Best valid loss before this validation: 2.725270
0.80 elbo_t 3.727525 rc_loss 1.614629 kl_loss 0.003240 bow_loss 2.109656 
0.80 elbo_t 3.372596 rc_loss 1.610881 kl_loss 0.003156 bow_loss 1.758559 
0.90 elbo_t 3.728995 rc_loss 1.614824 kl_loss 0.003125 bow_loss 2.111045 
0.90 elbo_t 3.373834 rc_loss 1.611053 kl_loss 0.003046 bow_loss 1.759734 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.300236 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 11
Learning rate 0.001000
1.00 elbo_t 3.727895 rc_loss 1.614002 kl_loss 0.003127 bow_loss 2.110767 
Epoch Done elbo_t 3.727895 rc_loss 1.614002 kl_loss 0.003127 bow_loss 2.110767 step time 15.1812
1.00 elbo_t 3.372871 rc_loss 1.610304 kl_loss 0.003024 bow_loss 1.759542 
Epoch Done elbo_t 3.372871 rc_loss 1.610304 kl_loss 0.003024 bow_loss 1.759542 step time 15.1539
Best valid loss before this validation: 3.799674
Best valid loss before this validation: 3.442281
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.647509 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 11
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.172881 rc_loss 1.477239 kl_loss 0.001991 bow_loss 0.693651 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.512456 rc_loss 1.470512 kl_loss 0.002100 bow_loss 1.039845 
0.20 elbo_t 2.230476 rc_loss 1.530288 kl_loss 0.002382 bow_loss 0.697805 
0.20 elbo_t 2.572242 rc_loss 1.523677 kl_loss 0.002500 bow_loss 1.046065 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.718916 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.363361 
Get a smaller valid loss, update the best valid loss
Saving the model
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 11
Learning rate 0.001000
>> Epoch 11
Learning rate 0.001000
0.30 elbo_t 2.233095 rc_loss 1.531965 kl_loss 0.002486 bow_loss 0.698644 
0.30 elbo_t 2.575058 rc_loss 1.525081 kl_loss 0.002568 bow_loss 1.047409 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.218573 rc_loss 1.483358 kl_loss 0.002232 bow_loss 1.732982 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.567359 rc_loss 1.486964 kl_loss 0.002324 bow_loss 2.078071 
0.40 elbo_t 2.247161 rc_loss 1.544439 kl_loss 0.002555 bow_loss 0.700167 
0.40 elbo_t 2.589507 rc_loss 1.537204 kl_loss 0.002600 bow_loss 1.049703 
0.20 elbo_t 3.281547 rc_loss 1.535281 kl_loss 0.002564 bow_loss 1.743702 
0.20 elbo_t 3.631532 rc_loss 1.538493 kl_loss 0.002608 bow_loss 2.090431 
0.50 elbo_t 2.243956 rc_loss 1.540098 kl_loss 0.002701 bow_loss 0.701158 
0.50 elbo_t 2.586835 rc_loss 1.532798 kl_loss 0.002788 bow_loss 1.051249 
0.30 elbo_t 3.284279 rc_loss 1.536186 kl_loss 0.002637 bow_loss 1.745455 
0.30 elbo_t 3.634902 rc_loss 1.539504 kl_loss 0.002708 bow_loss 2.092690 
0.60 elbo_t 2.246832 rc_loss 1.541954 kl_loss 0.002842 bow_loss 0.702036 
0.60 elbo_t 2.590013 rc_loss 1.534427 kl_loss 0.002948 bow_loss 1.052638 
0.40 elbo_t 3.300073 rc_loss 1.548454 kl_loss 0.002663 bow_loss 1.748956 
0.40 elbo_t 3.651388 rc_loss 1.551431 kl_loss 0.002745 bow_loss 2.097211 
0.70 elbo_t 2.242321 rc_loss 1.538133 kl_loss 0.002791 bow_loss 0.701397 
0.70 elbo_t 2.585144 rc_loss 1.530581 kl_loss 0.002870 bow_loss 1.051692 
0.50 elbo_t 3.298180 rc_loss 1.544003 kl_loss 0.002892 bow_loss 1.751286 
0.50 elbo_t 3.649878 rc_loss 1.546823 kl_loss 0.002979 bow_loss 2.100076 
0.80 elbo_t 2.241602 rc_loss 1.536992 kl_loss 0.002702 bow_loss 0.701908 
0.80 elbo_t 2.584682 rc_loss 1.529405 kl_loss 0.002798 bow_loss 1.052478 
0.60 elbo_t 3.302179 rc_loss 1.545658 kl_loss 0.003066 bow_loss 1.753455 
0.60 elbo_t 3.654496 rc_loss 1.548461 kl_loss 0.003166 bow_loss 2.102870 
0.90 elbo_t 2.241831 rc_loss 1.536069 kl_loss 0.002784 bow_loss 0.702978 
0.90 elbo_t 2.585585 rc_loss 1.528614 kl_loss 0.002888 bow_loss 1.054083 
0.70 elbo_t 3.296704 rc_loss 1.542049 kl_loss 0.002950 bow_loss 1.751705 
0.70 elbo_t 3.648666 rc_loss 1.544844 kl_loss 0.003025 bow_loss 2.100796 
1.00 elbo_t 2.236226 rc_loss 1.530490 kl_loss 0.002723 bow_loss 0.703013 
Epoch Done elbo_t 2.236226 rc_loss 1.530490 kl_loss 0.002723 bow_loss 0.703013 step time 15.3353
Best valid loss before this validation: 2.300236
1.00 elbo_t 2.579994 rc_loss 1.523042 kl_loss 0.002825 bow_loss 1.054128 
Epoch Done elbo_t 2.579994 rc_loss 1.523042 kl_loss 0.002825 bow_loss 1.054128 step time 15.4010
Best valid loss before this validation: 2.647509
0.80 elbo_t 3.648693 rc_loss 1.543306 kl_loss 0.002970 bow_loss 2.102417 
0.80 elbo_t 3.296523 rc_loss 1.540654 kl_loss 0.002899 bow_loss 1.752971 
0.90 elbo_t 3.651213 rc_loss 1.542589 kl_loss 0.003070 bow_loss 2.105554 
0.90 elbo_t 3.298317 rc_loss 1.539847 kl_loss 0.002997 bow_loss 1.755473 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.235744 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 12
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.581292 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 12
Learning rate 0.001000
1.00 elbo_t 3.292728 rc_loss 1.534190 kl_loss 0.002928 bow_loss 1.755611 
Epoch Done elbo_t 3.292728 rc_loss 1.534190 kl_loss 0.002928 bow_loss 1.755611 step time 15.5975
1.00 elbo_t 3.645543 rc_loss 1.536905 kl_loss 0.002993 bow_loss 2.105645 
Epoch Done elbo_t 3.645543 rc_loss 1.536905 kl_loss 0.002993 bow_loss 2.105645 step time 15.6040
Best valid loss before this validation: 3.363361
Best valid loss before this validation: 3.718916
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.185081 rc_loss 1.478400 kl_loss 0.002412 bow_loss 0.704270 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.528742 rc_loss 1.470223 kl_loss 0.002403 bow_loss 1.056116 
0.20 elbo_t 2.205783 rc_loss 1.500340 kl_loss 0.002325 bow_loss 0.703119 
0.20 elbo_t 2.549193 rc_loss 1.492507 kl_loss 0.002311 bow_loss 1.054374 
0.30 elbo_t 2.207904 rc_loss 1.500865 kl_loss 0.002324 bow_loss 0.704716 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.649105 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 12
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.294885 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 12
Learning rate 0.001000
0.30 elbo_t 2.552326 rc_loss 1.493288 kl_loss 0.002355 bow_loss 1.056683 
0.40 elbo_t 2.205146 rc_loss 1.498195 kl_loss 0.002319 bow_loss 0.704633 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.594690 rc_loss 1.482557 kl_loss 0.002454 bow_loss 2.109679 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.241248 rc_loss 1.479822 kl_loss 0.002459 bow_loss 1.758966 
0.40 elbo_t 2.549278 rc_loss 1.490339 kl_loss 0.002337 bow_loss 1.056602 
0.50 elbo_t 2.197915 rc_loss 1.491894 kl_loss 0.002489 bow_loss 0.703533 
0.20 elbo_t 3.613853 rc_loss 1.505515 kl_loss 0.002405 bow_loss 2.105933 
0.20 elbo_t 3.261423 rc_loss 1.502751 kl_loss 0.002383 bow_loss 1.756289 
0.50 elbo_t 2.541366 rc_loss 1.483866 kl_loss 0.002519 bow_loss 1.054981 
0.60 elbo_t 2.191414 rc_loss 1.486626 kl_loss 0.002529 bow_loss 0.702259 
0.30 elbo_t 3.619321 rc_loss 1.506535 kl_loss 0.002463 bow_loss 2.110322 
0.30 elbo_t 3.266540 rc_loss 1.504158 kl_loss 0.002441 bow_loss 1.759942 
0.60 elbo_t 2.534017 rc_loss 1.478499 kl_loss 0.002564 bow_loss 1.052953 
0.70 elbo_t 2.175637 rc_loss 1.472424 kl_loss 0.002524 bow_loss 0.700689 
0.40 elbo_t 3.616085 rc_loss 1.503507 kl_loss 0.002400 bow_loss 2.110178 
0.40 elbo_t 3.263344 rc_loss 1.501159 kl_loss 0.002392 bow_loss 1.759792 
0.70 elbo_t 2.517709 rc_loss 1.464464 kl_loss 0.002561 bow_loss 1.050684 
0.50 elbo_t 3.605875 rc_loss 1.496764 kl_loss 0.002589 bow_loss 2.106522 
0.80 elbo_t 2.176378 rc_loss 1.473315 kl_loss 0.002499 bow_loss 0.700565 
0.50 elbo_t 3.253490 rc_loss 1.494093 kl_loss 0.002580 bow_loss 1.756816 
0.80 elbo_t 2.518442 rc_loss 1.465369 kl_loss 0.002542 bow_loss 1.050531 
0.60 elbo_t 3.596635 rc_loss 1.491739 kl_loss 0.002640 bow_loss 2.102256 
0.60 elbo_t 3.245198 rc_loss 1.489194 kl_loss 0.002633 bow_loss 1.753371 
0.90 elbo_t 2.177374 rc_loss 1.473773 kl_loss 0.002424 bow_loss 0.701177 
0.90 elbo_t 2.519711 rc_loss 1.465812 kl_loss 0.002472 bow_loss 1.051427 
0.70 elbo_t 3.577798 rc_loss 1.477677 kl_loss 0.002623 bow_loss 2.097498 
0.70 elbo_t 3.227474 rc_loss 1.475175 kl_loss 0.002628 bow_loss 1.749671 
1.00 elbo_t 2.172827 rc_loss 1.468905 kl_loss 0.002555 bow_loss 0.701367 
Epoch Done elbo_t 2.172827 rc_loss 1.468905 kl_loss 0.002555 bow_loss 0.701367 step time 15.4806
Best valid loss before this validation: 2.235744
1.00 elbo_t 2.515329 rc_loss 1.461027 kl_loss 0.002593 bow_loss 1.051709 
Epoch Done elbo_t 2.515329 rc_loss 1.461027 kl_loss 0.002593 bow_loss 1.051709 step time 15.4499
Best valid loss before this validation: 2.581292
0.80 elbo_t 3.578098 rc_loss 1.478374 kl_loss 0.002619 bow_loss 2.097104 
0.80 elbo_t 3.228020 rc_loss 1.476030 kl_loss 0.002615 bow_loss 1.749375 
0.90 elbo_t 3.580378 rc_loss 1.478945 kl_loss 0.002561 bow_loss 2.098872 
0.90 elbo_t 3.229887 rc_loss 1.476500 kl_loss 0.002556 bow_loss 1.750831 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.178207 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 13
Learning rate 0.001000
1.00 elbo_t 3.575936 rc_loss 1.473876 kl_loss 0.002657 bow_loss 2.099403 
Epoch Done elbo_t 3.575936 rc_loss 1.473876 kl_loss 0.002657 bow_loss 2.099403 step time 15.2493
Best valid loss before this validation: 3.649105
1.00 elbo_t 3.225543 rc_loss 1.471587 kl_loss 0.002661 bow_loss 1.751294 
Epoch Done elbo_t 3.225543 rc_loss 1.471587 kl_loss 0.002661 bow_loss 1.751294 step time 15.2279
Best valid loss before this validation: 3.294885
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.523221 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 13
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.122964 rc_loss 1.417128 kl_loss 0.001993 bow_loss 0.703844 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.466516 rc_loss 1.409155 kl_loss 0.002088 bow_loss 1.055274 
0.20 elbo_t 2.139251 rc_loss 1.435891 kl_loss 0.002093 bow_loss 0.701267 
0.20 elbo_t 2.481578 rc_loss 1.427870 kl_loss 0.002157 bow_loss 1.051551 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.584486 
Get a smaller valid loss, update the best valid loss
Saving the model
0.30 elbo_t 2.146661 rc_loss 1.442907 kl_loss 0.002151 bow_loss 0.701602 
>> Epoch 13
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.234684 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 13
Learning rate 0.001000
0.30 elbo_t 2.489719 rc_loss 1.435332 kl_loss 0.002180 bow_loss 1.052207 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.527391 rc_loss 1.421859 kl_loss 0.002326 bow_loss 2.103207 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.178770 rc_loss 1.419910 kl_loss 0.002279 bow_loss 1.756581 
0.40 elbo_t 2.147151 rc_loss 1.442006 kl_loss 0.002111 bow_loss 0.703034 
0.40 elbo_t 2.491311 rc_loss 1.434714 kl_loss 0.002123 bow_loss 1.054474 
0.20 elbo_t 3.537715 rc_loss 1.438955 kl_loss 0.002287 bow_loss 2.096473 
0.20 elbo_t 3.191693 rc_loss 1.438233 kl_loss 0.002248 bow_loss 1.751213 
0.50 elbo_t 2.135899 rc_loss 1.430977 kl_loss 0.002200 bow_loss 0.702722 
0.50 elbo_t 2.479936 rc_loss 1.423854 kl_loss 0.002222 bow_loss 1.053860 
0.30 elbo_t 3.546207 rc_loss 1.446233 kl_loss 0.002241 bow_loss 2.097733 
0.30 elbo_t 3.200316 rc_loss 1.445332 kl_loss 0.002225 bow_loss 1.752759 
0.60 elbo_t 2.128847 rc_loss 1.425327 kl_loss 0.002220 bow_loss 0.701300 
0.60 elbo_t 2.472033 rc_loss 1.418004 kl_loss 0.002249 bow_loss 1.051781 
0.40 elbo_t 3.550935 rc_loss 1.446224 kl_loss 0.002162 bow_loss 2.102549 
0.40 elbo_t 3.202772 rc_loss 1.444646 kl_loss 0.002151 bow_loss 1.755976 
0.70 elbo_t 2.114262 rc_loss 1.412332 kl_loss 0.002293 bow_loss 0.699637 
0.70 elbo_t 2.456869 rc_loss 1.405264 kl_loss 0.002323 bow_loss 1.049283 
0.50 elbo_t 3.538563 rc_loss 1.435105 kl_loss 0.002273 bow_loss 2.101185 
0.50 elbo_t 3.191816 rc_loss 1.433915 kl_loss 0.002254 bow_loss 1.755647 
0.80 elbo_t 2.114433 rc_loss 1.412210 kl_loss 0.002301 bow_loss 0.699923 
0.80 elbo_t 2.457141 rc_loss 1.404982 kl_loss 0.002325 bow_loss 1.049834 
0.60 elbo_t 3.529109 rc_loss 1.429954 kl_loss 0.002297 bow_loss 2.096857 
0.60 elbo_t 3.182490 rc_loss 1.428362 kl_loss 0.002283 bow_loss 1.751845 
0.90 elbo_t 2.111990 rc_loss 1.409867 kl_loss 0.002342 bow_loss 0.699782 
0.90 elbo_t 2.454661 rc_loss 1.402667 kl_loss 0.002350 bow_loss 1.049644 
0.70 elbo_t 3.511344 rc_loss 1.417081 kl_loss 0.002377 bow_loss 2.091886 
0.70 elbo_t 3.165441 rc_loss 1.415425 kl_loss 0.002365 bow_loss 1.747651 
1.00 elbo_t 2.112559 rc_loss 1.410105 kl_loss 0.002350 bow_loss 0.700104 
Epoch Done elbo_t 2.112559 rc_loss 1.410105 kl_loss 0.002350 bow_loss 0.700104 step time 15.5302
Best valid loss before this validation: 2.178207
1.00 elbo_t 2.455182 rc_loss 1.402683 kl_loss 0.002364 bow_loss 1.050134 
Epoch Done elbo_t 2.455182 rc_loss 1.402683 kl_loss 0.002364 bow_loss 1.050134 step time 15.5737
Best valid loss before this validation: 2.523221
0.80 elbo_t 3.512446 rc_loss 1.416811 kl_loss 0.002370 bow_loss 2.093266 
0.80 elbo_t 3.166067 rc_loss 1.415120 kl_loss 0.002358 bow_loss 1.748590 
0.90 elbo_t 3.510356 rc_loss 1.414533 kl_loss 0.002393 bow_loss 2.093430 
0.90 elbo_t 3.163154 rc_loss 1.412566 kl_loss 0.002379 bow_loss 1.748209 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.125600 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 14
Learning rate 0.001000
1.00 elbo_t 3.511470 rc_loss 1.414688 kl_loss 0.002408 bow_loss 2.094374 
Epoch Done elbo_t 3.511470 rc_loss 1.414688 kl_loss 0.002408 bow_loss 2.094374 step time 15.2219
Best valid loss before this validation: 3.584486
1.00 elbo_t 3.163971 rc_loss 1.412583 kl_loss 0.002394 bow_loss 1.748994 
Epoch Done elbo_t 3.163971 rc_loss 1.412583 kl_loss 0.002394 bow_loss 1.748994 step time 15.2218
Best valid loss before this validation: 3.234684
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.470029 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 14
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.099833 rc_loss 1.401593 kl_loss 0.002202 bow_loss 0.696038 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.439978 rc_loss 1.394116 kl_loss 0.002167 bow_loss 1.043696 
0.20 elbo_t 2.044639 rc_loss 1.351095 kl_loss 0.002445 bow_loss 0.691098 
0.20 elbo_t 2.382555 rc_loss 1.343880 kl_loss 0.002362 bow_loss 1.036313 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.528207 
Get a smaller valid loss, update the best valid loss
Saving the model
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.177741 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 14
Learning rate 0.001000
>> Epoch 14
Learning rate 0.001000
0.30 elbo_t 2.056583 rc_loss 1.360665 kl_loss 0.002513 bow_loss 0.693406 
0.30 elbo_t 2.395540 rc_loss 1.352994 kl_loss 0.002499 bow_loss 1.040047 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.489604 rc_loss 1.404363 kl_loss 0.002168 bow_loss 2.083074 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.142564 rc_loss 1.402846 kl_loss 0.002121 bow_loss 1.737597 
0.40 elbo_t 2.069109 rc_loss 1.371759 kl_loss 0.002527 bow_loss 0.694824 
0.40 elbo_t 2.409155 rc_loss 1.364339 kl_loss 0.002488 bow_loss 1.042328 
0.20 elbo_t 3.426092 rc_loss 1.355511 kl_loss 0.002433 bow_loss 2.068149 
0.20 elbo_t 3.080917 rc_loss 1.353328 kl_loss 0.002349 bow_loss 1.725241 
0.50 elbo_t 2.067729 rc_loss 1.370227 kl_loss 0.002758 bow_loss 0.694744 
0.50 elbo_t 2.407438 rc_loss 1.362491 kl_loss 0.002721 bow_loss 1.042226 
0.30 elbo_t 3.441383 rc_loss 1.364872 kl_loss 0.002623 bow_loss 2.073887 
0.30 elbo_t 3.096909 rc_loss 1.362823 kl_loss 0.002541 bow_loss 1.731544 
0.60 elbo_t 2.069962 rc_loss 1.371151 kl_loss 0.002660 bow_loss 0.696151 
0.60 elbo_t 2.410684 rc_loss 1.363631 kl_loss 0.002654 bow_loss 1.044399 
0.40 elbo_t 3.456928 rc_loss 1.375777 kl_loss 0.002573 bow_loss 2.078579 
0.40 elbo_t 3.111625 rc_loss 1.373923 kl_loss 0.002499 bow_loss 1.735204 
0.70 elbo_t 2.072351 rc_loss 1.373058 kl_loss 0.002640 bow_loss 0.696654 
0.70 elbo_t 2.412956 rc_loss 1.365122 kl_loss 0.002650 bow_loss 1.045183 
0.50 elbo_t 3.454484 rc_loss 1.373684 kl_loss 0.002795 bow_loss 2.078005 
0.50 elbo_t 3.109577 rc_loss 1.371683 kl_loss 0.002732 bow_loss 1.735161 
0.80 elbo_t 2.067215 rc_loss 1.368925 kl_loss 0.002687 bow_loss 0.695603 
0.60 elbo_t 3.459785 rc_loss 1.374740 kl_loss 0.002747 bow_loss 2.082298 
0.80 elbo_t 2.407225 rc_loss 1.360770 kl_loss 0.002690 bow_loss 1.043764 
0.60 elbo_t 3.114522 rc_loss 1.372581 kl_loss 0.002677 bow_loss 1.739264 
0.90 elbo_t 2.063981 rc_loss 1.365214 kl_loss 0.002689 bow_loss 0.696077 
0.70 elbo_t 3.463137 rc_loss 1.376502 kl_loss 0.002749 bow_loss 2.083885 
0.90 elbo_t 2.404450 rc_loss 1.356928 kl_loss 0.002701 bow_loss 1.044821 
0.70 elbo_t 3.117151 rc_loss 1.374133 kl_loss 0.002684 bow_loss 1.740334 
1.00 elbo_t 2.058620 rc_loss 1.359761 kl_loss 0.002750 bow_loss 0.696109 
Epoch Done elbo_t 2.058620 rc_loss 1.359761 kl_loss 0.002750 bow_loss 0.696109 step time 15.6332
Best valid loss before this validation: 2.125600
0.80 elbo_t 3.456182 rc_loss 1.372523 kl_loss 0.002774 bow_loss 2.080885 
0.80 elbo_t 3.111068 rc_loss 1.370150 kl_loss 0.002719 bow_loss 1.738200 
1.00 elbo_t 2.399268 rc_loss 1.351632 kl_loss 0.002770 bow_loss 1.044867 
Epoch Done elbo_t 2.399268 rc_loss 1.351632 kl_loss 0.002770 bow_loss 1.044867 step time 15.5338
Best valid loss before this validation: 2.470029
0.90 elbo_t 3.453339 rc_loss 1.368613 kl_loss 0.002807 bow_loss 2.081919 
0.90 elbo_t 3.108841 rc_loss 1.366284 kl_loss 0.002750 bow_loss 1.739808 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.077564 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 15
Learning rate 0.001000
1.00 elbo_t 3.448478 rc_loss 1.363557 kl_loss 0.002890 bow_loss 2.082031 
Epoch Done elbo_t 3.448478 rc_loss 1.363557 kl_loss 0.002890 bow_loss 2.082031 step time 15.1433
Best valid loss before this validation: 3.528207
1.00 elbo_t 3.103645 rc_loss 1.361147 kl_loss 0.002828 bow_loss 1.739669 
Epoch Done elbo_t 3.103645 rc_loss 1.361147 kl_loss 0.002828 bow_loss 1.739669 step time 15.1672
Best valid loss before this validation: 3.177741
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.425042 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 15
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.055179 rc_loss 1.350201 kl_loss 0.002801 bow_loss 0.702178 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.402362 rc_loss 1.344368 kl_loss 0.002769 bow_loss 1.055224 
0.20 elbo_t 2.054521 rc_loss 1.353714 kl_loss 0.002489 bow_loss 0.698318 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.470195 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 15
Learning rate 0.001000
0.20 elbo_t 2.400837 rc_loss 1.347676 kl_loss 0.002497 bow_loss 1.050664 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.129638 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 15
Learning rate 0.001000
0.30 elbo_t 2.039154 rc_loss 1.341832 kl_loss 0.002858 bow_loss 0.694464 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.455824 rc_loss 1.355419 kl_loss 0.002723 bow_loss 2.097682 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.111670 rc_loss 1.352670 kl_loss 0.002732 bow_loss 1.756267 
0.30 elbo_t 2.382806 rc_loss 1.335171 kl_loss 0.002910 bow_loss 1.044725 
0.40 elbo_t 2.033090 rc_loss 1.335614 kl_loss 0.002858 bow_loss 0.694618 
0.20 elbo_t 3.446831 rc_loss 1.357285 kl_loss 0.002571 bow_loss 2.086975 
0.20 elbo_t 3.105928 rc_loss 1.355099 kl_loss 0.002564 bow_loss 1.748265 
0.40 elbo_t 2.375062 rc_loss 1.328248 kl_loss 0.002857 bow_loss 1.043958 
0.50 elbo_t 2.025499 rc_loss 1.328060 kl_loss 0.002739 bow_loss 0.694700 
0.30 elbo_t 3.424916 rc_loss 1.345719 kl_loss 0.003118 bow_loss 2.076078 
0.30 elbo_t 3.083807 rc_loss 1.342896 kl_loss 0.003087 bow_loss 1.737823 
0.50 elbo_t 2.368046 rc_loss 1.320851 kl_loss 0.002768 bow_loss 1.044427 
0.60 elbo_t 2.025586 rc_loss 1.327902 kl_loss 0.002729 bow_loss 0.694955 
0.40 elbo_t 3.415346 rc_loss 1.338403 kl_loss 0.003029 bow_loss 2.073914 
0.40 elbo_t 3.075093 rc_loss 1.335742 kl_loss 0.002972 bow_loss 1.736379 
0.60 elbo_t 2.367891 rc_loss 1.320444 kl_loss 0.002756 bow_loss 1.044691 
0.70 elbo_t 2.012104 rc_loss 1.315288 kl_loss 0.002736 bow_loss 0.694080 
0.50 elbo_t 3.068296 rc_loss 1.328327 kl_loss 0.002922 bow_loss 1.737047 
0.50 elbo_t 3.408401 rc_loss 1.330920 kl_loss 0.002964 bow_loss 2.074517 
0.70 elbo_t 2.352759 rc_loss 1.307296 kl_loss 0.002751 bow_loss 1.042712 
0.80 elbo_t 2.015742 rc_loss 1.318688 kl_loss 0.002783 bow_loss 0.694271 
0.60 elbo_t 3.408819 rc_loss 1.330517 kl_loss 0.002951 bow_loss 2.075351 
0.60 elbo_t 3.068440 rc_loss 1.328124 kl_loss 0.002909 bow_loss 1.737406 
0.80 elbo_t 2.356824 rc_loss 1.310961 kl_loss 0.002819 bow_loss 1.043044 
0.90 elbo_t 2.017051 rc_loss 1.319914 kl_loss 0.002702 bow_loss 0.694435 
0.70 elbo_t 3.391299 rc_loss 1.317359 kl_loss 0.002933 bow_loss 2.071007 
0.70 elbo_t 3.051987 rc_loss 1.314971 kl_loss 0.002897 bow_loss 1.734118 
0.90 elbo_t 2.358280 rc_loss 1.312134 kl_loss 0.002739 bow_loss 1.043407 
1.00 elbo_t 2.012501 rc_loss 1.315410 kl_loss 0.002716 bow_loss 0.694374 
Epoch Done elbo_t 2.012501 rc_loss 1.315410 kl_loss 0.002716 bow_loss 0.694374 step time 15.4947
Best valid loss before this validation: 2.077564
0.80 elbo_t 3.396075 rc_loss 1.320986 kl_loss 0.002992 bow_loss 2.072097 
0.80 elbo_t 3.056314 rc_loss 1.318603 kl_loss 0.002955 bow_loss 1.734755 
1.00 elbo_t 2.354055 rc_loss 1.307919 kl_loss 0.002739 bow_loss 1.043397 
Epoch Done elbo_t 2.354055 rc_loss 1.307919 kl_loss 0.002739 bow_loss 1.043397 step time 15.4331
Best valid loss before this validation: 2.425042
0.90 elbo_t 3.398146 rc_loss 1.322127 kl_loss 0.002902 bow_loss 2.073117 
0.90 elbo_t 3.057810 rc_loss 1.319449 kl_loss 0.002868 bow_loss 1.735492 
1.00 elbo_t 3.393561 rc_loss 1.317962 kl_loss 0.002914 bow_loss 2.072685 
Epoch Done elbo_t 3.393561 rc_loss 1.317962 kl_loss 0.002914 bow_loss 2.072685 step time 15.1243
Best valid loss before this validation: 3.470195
1.00 elbo_t 3.053508 rc_loss 1.315254 kl_loss 0.002883 bow_loss 1.735371 
Epoch Done elbo_t 3.053508 rc_loss 1.315254 kl_loss 0.002883 bow_loss 1.735371 step time 15.1242
Best valid loss before this validation: 3.129638
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.036308 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 16
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.381740 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 16
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.011674 rc_loss 1.319364 kl_loss 0.001848 bow_loss 0.690462 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.352687 rc_loss 1.311704 kl_loss 0.001983 bow_loss 1.038999 
0.20 elbo_t 2.011261 rc_loss 1.315600 kl_loss 0.002770 bow_loss 0.692890 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.422869 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.082702 
Get a smaller valid loss, update the best valid loss
Saving the model
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 16
Learning rate 0.001000
>> Epoch 16
Learning rate 0.001000
0.20 elbo_t 2.351924 rc_loss 1.307934 kl_loss 0.002914 bow_loss 1.041076 
0.30 elbo_t 1.993248 rc_loss 1.300529 kl_loss 0.002529 bow_loss 0.690190 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.053891 rc_loss 1.321205 kl_loss 0.002117 bow_loss 1.730570 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.391875 rc_loss 1.321576 kl_loss 0.002142 bow_loss 2.068156 
0.30 elbo_t 2.332177 rc_loss 1.292895 kl_loss 0.002670 bow_loss 1.036613 
0.40 elbo_t 1.994873 rc_loss 1.299931 kl_loss 0.002636 bow_loss 0.692306 
0.20 elbo_t 3.059554 rc_loss 1.317402 kl_loss 0.003029 bow_loss 1.739122 
0.20 elbo_t 3.394205 rc_loss 1.318617 kl_loss 0.002996 bow_loss 2.072591 
0.40 elbo_t 2.335698 rc_loss 1.292507 kl_loss 0.002819 bow_loss 1.040373 
0.50 elbo_t 1.974031 rc_loss 1.281506 kl_loss 0.002620 bow_loss 0.689906 
0.30 elbo_t 3.370838 rc_loss 1.304521 kl_loss 0.002765 bow_loss 2.063551 
0.30 elbo_t 3.038108 rc_loss 1.302855 kl_loss 0.002808 bow_loss 1.732446 
0.50 elbo_t 2.313875 rc_loss 1.274160 kl_loss 0.002747 bow_loss 1.036968 
0.60 elbo_t 1.978614 rc_loss 1.285650 kl_loss 0.002662 bow_loss 0.690302 
0.40 elbo_t 3.044116 rc_loss 1.302763 kl_loss 0.003010 bow_loss 1.738342 
0.40 elbo_t 3.377797 rc_loss 1.304259 kl_loss 0.002967 bow_loss 2.070570 
0.60 elbo_t 2.318607 rc_loss 1.278339 kl_loss 0.002805 bow_loss 1.037463 
0.70 elbo_t 1.979516 rc_loss 1.286008 kl_loss 0.002749 bow_loss 0.690760 
0.50 elbo_t 3.019462 rc_loss 1.283992 kl_loss 0.002893 bow_loss 1.732578 
0.50 elbo_t 3.351372 rc_loss 1.285294 kl_loss 0.002837 bow_loss 2.063242 
0.70 elbo_t 2.319634 rc_loss 1.278650 kl_loss 0.002897 bow_loss 1.038086 
0.80 elbo_t 1.972836 rc_loss 1.279330 kl_loss 0.002809 bow_loss 0.690697 
0.60 elbo_t 3.356269 rc_loss 1.288953 kl_loss 0.002885 bow_loss 2.064431 
0.60 elbo_t 3.024102 rc_loss 1.287769 kl_loss 0.002957 bow_loss 1.733376 
0.80 elbo_t 2.312695 rc_loss 1.271897 kl_loss 0.002959 bow_loss 1.037839 
0.90 elbo_t 1.970046 rc_loss 1.276819 kl_loss 0.002811 bow_loss 0.690416 
0.70 elbo_t 3.024630 rc_loss 1.287684 kl_loss 0.003072 bow_loss 1.733874 
0.70 elbo_t 3.357738 rc_loss 1.289058 kl_loss 0.003002 bow_loss 2.065677 
0.90 elbo_t 2.309611 rc_loss 1.269262 kl_loss 0.002963 bow_loss 1.037386 
1.00 elbo_t 1.966722 rc_loss 1.273468 kl_loss 0.002815 bow_loss 0.690440 
Epoch Done elbo_t 1.966722 rc_loss 1.273468 kl_loss 0.002815 bow_loss 0.690440 step time 15.5763
Best valid loss before this validation: 2.036308
0.80 elbo_t 3.017610 rc_loss 1.280853 kl_loss 0.003147 bow_loss 1.733610 
0.80 elbo_t 3.351159 rc_loss 1.282437 kl_loss 0.003064 bow_loss 2.065657 
1.00 elbo_t 2.306329 rc_loss 1.265819 kl_loss 0.002960 bow_loss 1.037550 
Epoch Done elbo_t 2.306329 rc_loss 1.265819 kl_loss 0.002960 bow_loss 1.037550 step time 15.4834
Best valid loss before this validation: 2.381740
0.90 elbo_t 3.014010 rc_loss 1.278101 kl_loss 0.003159 bow_loss 1.732750 
0.90 elbo_t 3.347754 rc_loss 1.279686 kl_loss 0.003067 bow_loss 2.065000 
1.00 elbo_t 3.010429 rc_loss 1.274559 kl_loss 0.003168 bow_loss 1.732701 
Epoch Done elbo_t 3.010429 rc_loss 1.274559 kl_loss 0.003168 bow_loss 1.732701 step time 15.3441
Best valid loss before this validation: 3.082702
1.00 elbo_t 3.344323 rc_loss 1.276049 kl_loss 0.003064 bow_loss 2.065210 
Epoch Done elbo_t 3.344323 rc_loss 1.276049 kl_loss 0.003064 bow_loss 2.065210 step time 15.4039
Best valid loss before this validation: 3.422869
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.998902 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 17
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.343580 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 17
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.957737 rc_loss 1.265139 kl_loss 0.002554 bow_loss 0.690044 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.296312 rc_loss 1.255620 kl_loss 0.002445 bow_loss 1.038247 
0.20 elbo_t 1.946278 rc_loss 1.255430 kl_loss 0.002858 bow_loss 0.687990 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.041701 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 17
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.379880 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 17
Learning rate 0.001000
0.20 elbo_t 2.284278 rc_loss 1.246687 kl_loss 0.002761 bow_loss 1.034830 
0.30 elbo_t 1.951475 rc_loss 1.259239 kl_loss 0.002984 bow_loss 0.689252 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.994444 rc_loss 1.262185 kl_loss 0.002743 bow_loss 1.729516 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.331154 rc_loss 1.263601 kl_loss 0.002524 bow_loss 2.065030 
0.30 elbo_t 2.290578 rc_loss 1.250468 kl_loss 0.002971 bow_loss 1.037139 
0.40 elbo_t 1.937756 rc_loss 1.246055 kl_loss 0.003085 bow_loss 0.688617 
0.20 elbo_t 2.980002 rc_loss 1.252177 kl_loss 0.002880 bow_loss 1.724945 
0.20 elbo_t 3.318281 rc_loss 1.254270 kl_loss 0.002770 bow_loss 2.061242 
0.40 elbo_t 2.277066 rc_loss 1.238025 kl_loss 0.003089 bow_loss 1.035952 
0.50 elbo_t 1.920335 rc_loss 1.230820 kl_loss 0.003138 bow_loss 0.686376 
0.30 elbo_t 2.987453 rc_loss 1.256124 kl_loss 0.003037 bow_loss 1.728292 
0.30 elbo_t 3.326856 rc_loss 1.258459 kl_loss 0.002966 bow_loss 2.065431 
0.50 elbo_t 2.258957 rc_loss 1.223179 kl_loss 0.003142 bow_loss 1.032635 
0.60 elbo_t 1.918809 rc_loss 1.228909 kl_loss 0.003077 bow_loss 0.686824 
0.40 elbo_t 2.974594 rc_loss 1.244162 kl_loss 0.003295 bow_loss 1.727136 
0.40 elbo_t 3.313187 rc_loss 1.246380 kl_loss 0.003146 bow_loss 2.063661 
0.60 elbo_t 2.259050 rc_loss 1.221621 kl_loss 0.003108 bow_loss 1.034320 
0.70 elbo_t 1.924711 rc_loss 1.234387 kl_loss 0.003010 bow_loss 0.687314 
0.50 elbo_t 2.954340 rc_loss 1.229211 kl_loss 0.003408 bow_loss 1.721720 
0.50 elbo_t 3.292923 rc_loss 1.231223 kl_loss 0.003233 bow_loss 2.058467 
0.70 elbo_t 2.265401 rc_loss 1.227337 kl_loss 0.003050 bow_loss 1.035014 
0.80 elbo_t 1.928286 rc_loss 1.236988 kl_loss 0.002894 bow_loss 0.688404 
0.60 elbo_t 2.953606 rc_loss 1.227465 kl_loss 0.003364 bow_loss 1.722776 
0.60 elbo_t 3.291961 rc_loss 1.229324 kl_loss 0.003211 bow_loss 2.059426 
0.80 elbo_t 2.270214 rc_loss 1.230001 kl_loss 0.002910 bow_loss 1.037302 
0.70 elbo_t 2.960357 rc_loss 1.232892 kl_loss 0.003343 bow_loss 1.724122 
0.90 elbo_t 1.931050 rc_loss 1.239961 kl_loss 0.002872 bow_loss 0.688217 
0.70 elbo_t 3.299409 rc_loss 1.234996 kl_loss 0.003178 bow_loss 2.061234 
0.90 elbo_t 2.273933 rc_loss 1.233053 kl_loss 0.002887 bow_loss 1.037993 
0.80 elbo_t 3.305954 rc_loss 1.237962 kl_loss 0.003025 bow_loss 2.064966 
0.80 elbo_t 2.965390 rc_loss 1.235618 kl_loss 0.003193 bow_loss 1.726579 
1.00 elbo_t 1.927860 rc_loss 1.237571 kl_loss 0.002786 bow_loss 0.687504 
Epoch Done elbo_t 1.927860 rc_loss 1.237571 kl_loss 0.002786 bow_loss 0.687504 step time 15.5579
Best valid loss before this validation: 1.998902
1.00 elbo_t 2.270200 rc_loss 1.230517 kl_loss 0.002818 bow_loss 1.036864 
Epoch Done elbo_t 2.270200 rc_loss 1.230517 kl_loss 0.002818 bow_loss 1.036864 step time 15.5373
Best valid loss before this validation: 2.343580
0.90 elbo_t 3.308333 rc_loss 1.240678 kl_loss 0.002994 bow_loss 2.064661 
0.90 elbo_t 2.967614 rc_loss 1.238353 kl_loss 0.003145 bow_loss 1.726116 
1.00 elbo_t 3.304131 rc_loss 1.238456 kl_loss 0.002911 bow_loss 2.062764 
Epoch Done elbo_t 3.304131 rc_loss 1.238456 kl_loss 0.002911 bow_loss 2.062764 step time 15.2239
Best valid loss before this validation: 3.379880
1.00 elbo_t 2.963630 rc_loss 1.236010 kl_loss 0.003040 bow_loss 1.724580 
Epoch Done elbo_t 2.963630 rc_loss 1.236010 kl_loss 0.003040 bow_loss 1.724580 step time 15.3080
Best valid loss before this validation: 3.041701
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.967868 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 18
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.315536 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 18
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.898736 rc_loss 1.212800 kl_loss 0.002529 bow_loss 0.683406 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.240103 rc_loss 1.204705 kl_loss 0.002577 bow_loss 1.032821 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.346893 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 18
Learning rate 0.001000
0.20 elbo_t 1.895662 rc_loss 1.211779 kl_loss 0.002103 bow_loss 0.681780 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.006992 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 18
Learning rate 0.001000
0.20 elbo_t 2.236583 rc_loss 1.204042 kl_loss 0.002171 bow_loss 1.030370 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.260777 rc_loss 1.209838 kl_loss 0.002768 bow_loss 2.048171 
0.30 elbo_t 1.900106 rc_loss 1.214039 kl_loss 0.002054 bow_loss 0.684014 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.923577 rc_loss 1.207716 kl_loss 0.003073 bow_loss 1.712789 
0.30 elbo_t 2.243684 rc_loss 1.207201 kl_loss 0.002121 bow_loss 1.034362 
0.20 elbo_t 3.256128 rc_loss 1.211390 kl_loss 0.002214 bow_loss 2.042524 
0.20 elbo_t 2.918752 rc_loss 1.208766 kl_loss 0.002379 bow_loss 1.707607 
0.40 elbo_t 1.906669 rc_loss 1.220417 kl_loss 0.002017 bow_loss 0.684234 
0.40 elbo_t 2.248804 rc_loss 1.213473 kl_loss 0.002094 bow_loss 1.033237 
0.30 elbo_t 3.266574 rc_loss 1.214156 kl_loss 0.002217 bow_loss 2.050201 
0.30 elbo_t 2.927970 rc_loss 1.211710 kl_loss 0.002355 bow_loss 1.713905 
0.50 elbo_t 1.897593 rc_loss 1.210267 kl_loss 0.002087 bow_loss 0.685239 
0.50 elbo_t 2.239177 rc_loss 1.202947 kl_loss 0.002168 bow_loss 1.034061 
0.40 elbo_t 3.273181 rc_loss 1.219841 kl_loss 0.002221 bow_loss 2.051119 
0.40 elbo_t 2.934721 rc_loss 1.217963 kl_loss 0.002332 bow_loss 1.714426 
0.60 elbo_t 1.901792 rc_loss 1.214310 kl_loss 0.002111 bow_loss 0.685371 
0.60 elbo_t 2.244474 rc_loss 1.207394 kl_loss 0.002189 bow_loss 1.034890 
0.50 elbo_t 3.265338 rc_loss 1.209719 kl_loss 0.002286 bow_loss 2.053334 
0.50 elbo_t 2.926112 rc_loss 1.207657 kl_loss 0.002340 bow_loss 1.716117 
0.70 elbo_t 1.904697 rc_loss 1.215891 kl_loss 0.002101 bow_loss 0.686706 
0.70 elbo_t 2.247945 rc_loss 1.209116 kl_loss 0.002169 bow_loss 1.036660 
0.60 elbo_t 3.268901 rc_loss 1.213617 kl_loss 0.002278 bow_loss 2.053006 
0.60 elbo_t 2.930387 rc_loss 1.211674 kl_loss 0.002343 bow_loss 1.716371 
0.80 elbo_t 1.900463 rc_loss 1.211034 kl_loss 0.002211 bow_loss 0.687218 
0.80 elbo_t 2.242939 rc_loss 1.204127 kl_loss 0.002275 bow_loss 1.036536 
0.70 elbo_t 3.274870 rc_loss 1.215581 kl_loss 0.002263 bow_loss 2.057026 
0.70 elbo_t 2.935416 rc_loss 1.213571 kl_loss 0.002320 bow_loss 1.719526 
0.90 elbo_t 1.891718 rc_loss 1.203124 kl_loss 0.002328 bow_loss 0.686266 
0.90 elbo_t 2.232940 rc_loss 1.196178 kl_loss 0.002408 bow_loss 1.034354 
0.80 elbo_t 3.271013 rc_loss 1.210737 kl_loss 0.002373 bow_loss 2.057904 
0.80 elbo_t 2.931346 rc_loss 1.208680 kl_loss 0.002431 bow_loss 1.720235 
1.00 elbo_t 1.894176 rc_loss 1.204996 kl_loss 0.002288 bow_loss 0.686891 
Epoch Done elbo_t 1.894176 rc_loss 1.204996 kl_loss 0.002288 bow_loss 0.686891 step time 15.5035
Best valid loss before this validation: 1.967868
1.00 elbo_t 2.235550 rc_loss 1.197881 kl_loss 0.002364 bow_loss 1.035305 
Epoch Done elbo_t 2.235550 rc_loss 1.197881 kl_loss 0.002364 bow_loss 1.035305 step time 15.3969
Best valid loss before this validation: 2.315536
0.90 elbo_t 3.259563 rc_loss 1.202443 kl_loss 0.002516 bow_loss 2.054604 
0.90 elbo_t 2.920235 rc_loss 1.200369 kl_loss 0.002553 bow_loss 1.717313 
1.00 elbo_t 3.263669 rc_loss 1.204063 kl_loss 0.002461 bow_loss 2.057145 
Epoch Done elbo_t 3.263669 rc_loss 1.204063 kl_loss 0.002461 bow_loss 2.057145 step time 15.2588
Best valid loss before this validation: 3.346893
1.00 elbo_t 2.923512 rc_loss 1.201954 kl_loss 0.002501 bow_loss 1.719056 
Epoch Done elbo_t 2.923512 rc_loss 1.201954 kl_loss 0.002501 bow_loss 1.719056 step time 15.2375
Best valid loss before this validation: 3.006992
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.940699 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 19
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.283677 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 19
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.862333 rc_loss 1.174894 kl_loss 0.003364 bow_loss 0.684074 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.197166 rc_loss 1.164683 kl_loss 0.003157 bow_loss 1.029327 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.974199 
Get a smaller valid loss, update the best valid loss
Saving the model
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.316359 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 19
Learning rate 0.001000
>> Epoch 19
Learning rate 0.001000
0.20 elbo_t 1.859426 rc_loss 1.174371 kl_loss 0.003136 bow_loss 0.681918 
0.20 elbo_t 2.191955 rc_loss 1.165019 kl_loss 0.002839 bow_loss 1.024097 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.881806 rc_loss 1.169012 kl_loss 0.003447 bow_loss 1.709347 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.222312 rc_loss 1.170460 kl_loss 0.003506 bow_loss 2.048346 
0.30 elbo_t 1.851554 rc_loss 1.165575 kl_loss 0.002775 bow_loss 0.683203 
0.30 elbo_t 2.185015 rc_loss 1.156524 kl_loss 0.002618 bow_loss 1.025873 
0.20 elbo_t 2.877799 rc_loss 1.171005 kl_loss 0.003038 bow_loss 1.703756 
0.20 elbo_t 3.218165 rc_loss 1.172984 kl_loss 0.003168 bow_loss 2.042013 
0.40 elbo_t 1.836108 rc_loss 1.152411 kl_loss 0.002770 bow_loss 0.680926 
0.40 elbo_t 2.170480 rc_loss 1.144742 kl_loss 0.002636 bow_loss 1.023101 
0.30 elbo_t 2.872808 rc_loss 1.162282 kl_loss 0.002764 bow_loss 1.707762 
0.30 elbo_t 3.214262 rc_loss 1.164203 kl_loss 0.002823 bow_loss 2.047236 
0.50 elbo_t 1.845415 rc_loss 1.160382 kl_loss 0.002788 bow_loss 0.682245 
0.50 elbo_t 2.180891 rc_loss 1.152649 kl_loss 0.002679 bow_loss 1.025563 
0.40 elbo_t 2.854527 rc_loss 1.149481 kl_loss 0.002750 bow_loss 1.702296 
0.40 elbo_t 3.195220 rc_loss 1.151159 kl_loss 0.002793 bow_loss 2.041267 
0.60 elbo_t 1.853359 rc_loss 1.167493 kl_loss 0.002762 bow_loss 0.683104 
0.60 elbo_t 2.189546 rc_loss 1.160012 kl_loss 0.002637 bow_loss 1.026896 
0.50 elbo_t 3.208626 rc_loss 1.159016 kl_loss 0.002792 bow_loss 2.046817 
0.50 elbo_t 2.866735 rc_loss 1.157307 kl_loss 0.002796 bow_loss 1.706633 
0.70 elbo_t 1.851386 rc_loss 1.164705 kl_loss 0.002902 bow_loss 0.683780 
0.70 elbo_t 2.187803 rc_loss 1.157154 kl_loss 0.002790 bow_loss 1.027859 
0.60 elbo_t 3.218383 rc_loss 1.165926 kl_loss 0.002800 bow_loss 2.049658 
0.60 elbo_t 2.875700 rc_loss 1.164312 kl_loss 0.002832 bow_loss 1.708556 
0.80 elbo_t 1.855836 rc_loss 1.167954 kl_loss 0.003043 bow_loss 0.684838 
0.80 elbo_t 2.192844 rc_loss 1.160496 kl_loss 0.002917 bow_loss 1.029431 
0.70 elbo_t 3.218479 rc_loss 1.163221 kl_loss 0.002920 bow_loss 2.052338 
0.70 elbo_t 2.875152 rc_loss 1.161677 kl_loss 0.002955 bow_loss 1.710519 
0.90 elbo_t 1.858088 rc_loss 1.170463 kl_loss 0.002889 bow_loss 0.684736 
0.90 elbo_t 2.195558 rc_loss 1.163357 kl_loss 0.002803 bow_loss 1.029398 
0.80 elbo_t 3.225442 rc_loss 1.166924 kl_loss 0.003051 bow_loss 2.055467 
0.80 elbo_t 2.881650 rc_loss 1.165279 kl_loss 0.003109 bow_loss 1.713262 
1.00 elbo_t 1.860306 rc_loss 1.172353 kl_loss 0.002872 bow_loss 0.685081 
Epoch Done elbo_t 1.860306 rc_loss 1.172353 kl_loss 0.002872 bow_loss 0.685081 step time 15.4200
Best valid loss before this validation: 1.940699
1.00 elbo_t 2.197706 rc_loss 1.165056 kl_loss 0.002760 bow_loss 1.029891 
Epoch Done elbo_t 2.197706 rc_loss 1.165056 kl_loss 0.002760 bow_loss 1.029891 step time 15.3619
Best valid loss before this validation: 2.283677
0.90 elbo_t 3.228253 rc_loss 1.169725 kl_loss 0.002913 bow_loss 2.055615 
0.90 elbo_t 2.884495 rc_loss 1.167932 kl_loss 0.002992 bow_loss 1.713572 
1.00 elbo_t 3.231181 rc_loss 1.171463 kl_loss 0.002869 bow_loss 2.056849 
Epoch Done elbo_t 3.231181 rc_loss 1.171463 kl_loss 0.002869 bow_loss 2.056849 step time 15.3532
Best valid loss before this validation: 3.316359
1.00 elbo_t 2.887083 rc_loss 1.169645 kl_loss 0.002923 bow_loss 1.714514 
Epoch Done elbo_t 2.887083 rc_loss 1.169645 kl_loss 0.002923 bow_loss 1.714514 step time 15.4343
Best valid loss before this validation: 2.974199
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.913281 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 20
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.253567 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 20
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.879627 rc_loss 1.188836 kl_loss 0.002846 bow_loss 0.687944 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.215608 rc_loss 1.179886 kl_loss 0.002908 bow_loss 1.032814 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.290101 
Get a smaller valid loss, update the best valid loss
Saving the model
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.943948 
>> Epoch 20
Learning rate 0.001000
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 20
Learning rate 0.001000
0.20 elbo_t 1.844181 rc_loss 1.155885 kl_loss 0.002317 bow_loss 0.685979 
0.20 elbo_t 2.179578 rc_loss 1.147646 kl_loss 0.002415 bow_loss 1.029517 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.254920 rc_loss 1.185921 kl_loss 0.002893 bow_loss 2.066106 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.907570 rc_loss 1.183955 kl_loss 0.002811 bow_loss 1.720804 
0.30 elbo_t 1.817774 rc_loss 1.133876 kl_loss 0.002335 bow_loss 0.681562 
0.30 elbo_t 2.151471 rc_loss 1.126092 kl_loss 0.002557 bow_loss 1.022822 
0.20 elbo_t 3.214682 rc_loss 1.153360 kl_loss 0.002446 bow_loss 2.058876 
0.20 elbo_t 2.868026 rc_loss 1.150444 kl_loss 0.002348 bow_loss 1.715234 
0.40 elbo_t 1.817502 rc_loss 1.132541 kl_loss 0.002322 bow_loss 0.682639 
0.40 elbo_t 2.152829 rc_loss 1.125663 kl_loss 0.002566 bow_loss 1.024599 
0.30 elbo_t 3.178214 rc_loss 1.130519 kl_loss 0.002555 bow_loss 2.045139 
0.30 elbo_t 2.834789 rc_loss 1.128061 kl_loss 0.002462 bow_loss 1.704266 
0.50 elbo_t 1.826762 rc_loss 1.141804 kl_loss 0.002321 bow_loss 0.682637 
0.50 elbo_t 2.162428 rc_loss 1.135064 kl_loss 0.002577 bow_loss 1.024788 
0.40 elbo_t 3.181206 rc_loss 1.130452 kl_loss 0.002546 bow_loss 2.048208 
0.40 elbo_t 2.837806 rc_loss 1.128171 kl_loss 0.002442 bow_loss 1.707193 
0.60 elbo_t 1.832444 rc_loss 1.146996 kl_loss 0.002336 bow_loss 0.683113 
0.60 elbo_t 2.168619 rc_loss 1.140480 kl_loss 0.002547 bow_loss 1.025592 
0.50 elbo_t 3.190810 rc_loss 1.140176 kl_loss 0.002588 bow_loss 2.048046 
0.50 elbo_t 2.847808 rc_loss 1.137900 kl_loss 0.002516 bow_loss 1.707392 
0.70 elbo_t 2.165980 rc_loss 1.138638 kl_loss 0.002585 bow_loss 1.024758 
0.70 elbo_t 1.829955 rc_loss 1.145198 kl_loss 0.002353 bow_loss 0.682403 
0.60 elbo_t 2.855153 rc_loss 1.143666 kl_loss 0.002480 bow_loss 1.709007 
0.60 elbo_t 3.198283 rc_loss 1.146027 kl_loss 0.002593 bow_loss 2.049662 
0.80 elbo_t 2.170829 rc_loss 1.141479 kl_loss 0.002622 bow_loss 1.026728 
0.80 elbo_t 1.834180 rc_loss 1.148182 kl_loss 0.002377 bow_loss 0.683621 
0.70 elbo_t 2.851787 rc_loss 1.141995 kl_loss 0.002464 bow_loss 1.707328 
0.70 elbo_t 3.194649 rc_loss 1.144670 kl_loss 0.002589 bow_loss 2.047390 
0.90 elbo_t 2.169065 rc_loss 1.139760 kl_loss 0.002556 bow_loss 1.026749 
0.90 elbo_t 1.832691 rc_loss 1.146786 kl_loss 0.002324 bow_loss 0.683581 
0.80 elbo_t 2.858036 rc_loss 1.144975 kl_loss 0.002513 bow_loss 1.710548 
0.80 elbo_t 3.201393 rc_loss 1.147623 kl_loss 0.002603 bow_loss 2.051167 
1.00 elbo_t 2.169841 rc_loss 1.140219 kl_loss 0.002568 bow_loss 1.027054 
Epoch Done elbo_t 2.169841 rc_loss 1.140219 kl_loss 0.002568 bow_loss 1.027054 step time 15.0341
Best valid loss before this validation: 2.253567
1.00 elbo_t 1.833473 rc_loss 1.147286 kl_loss 0.002333 bow_loss 0.683854 
Epoch Done elbo_t 1.833473 rc_loss 1.147286 kl_loss 0.002333 bow_loss 0.683854 step time 15.2992
Best valid loss before this validation: 1.913281
0.90 elbo_t 2.855983 rc_loss 1.143232 kl_loss 0.002473 bow_loss 1.710278 
0.90 elbo_t 3.199167 rc_loss 1.145705 kl_loss 0.002553 bow_loss 2.050908 
1.00 elbo_t 2.856915 rc_loss 1.143565 kl_loss 0.002468 bow_loss 1.710882 
Epoch Done elbo_t 2.856915 rc_loss 1.143565 kl_loss 0.002468 bow_loss 1.710882 step time 15.0958
Best valid loss before this validation: 2.943948
1.00 elbo_t 3.199840 rc_loss 1.145949 kl_loss 0.002557 bow_loss 2.051334 
Epoch Done elbo_t 3.199840 rc_loss 1.145949 kl_loss 0.002557 bow_loss 2.051334 step time 15.1922
Best valid loss before this validation: 3.290101
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.229492 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 21
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.890069 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 21
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.172998 rc_loss 1.140596 kl_loss 0.003307 bow_loss 1.029095 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.839553 rc_loss 1.150548 kl_loss 0.002931 bow_loss 0.686073 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.919035 
Get a smaller valid loss, update the best valid loss
Saving the model
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.263586 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 21
Learning rate 0.001000
>> Epoch 21
Learning rate 0.001000
0.20 elbo_t 2.174468 rc_loss 1.144983 kl_loss 0.002854 bow_loss 1.026631 
0.20 elbo_t 1.839775 rc_loss 1.153010 kl_loss 0.002547 bow_loss 0.684219 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.862201 rc_loss 1.143809 kl_loss 0.003620 bow_loss 1.714773 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.205095 rc_loss 1.147190 kl_loss 0.003448 bow_loss 2.054457 
0.30 elbo_t 2.139325 rc_loss 1.115952 kl_loss 0.002918 bow_loss 1.020454 
0.30 elbo_t 1.806263 rc_loss 1.123403 kl_loss 0.002606 bow_loss 0.680254 
0.20 elbo_t 2.863775 rc_loss 1.148500 kl_loss 0.003127 bow_loss 1.712148 
0.20 elbo_t 3.204105 rc_loss 1.151187 kl_loss 0.003000 bow_loss 2.049918 
0.40 elbo_t 2.136138 rc_loss 1.114512 kl_loss 0.002837 bow_loss 1.018789 
0.40 elbo_t 1.803900 rc_loss 1.121801 kl_loss 0.002591 bow_loss 0.679507 
0.30 elbo_t 2.824832 rc_loss 1.118679 kl_loss 0.002996 bow_loss 1.703157 
0.30 elbo_t 3.161601 rc_loss 1.121177 kl_loss 0.003046 bow_loss 2.037378 
0.50 elbo_t 2.145017 rc_loss 1.119941 kl_loss 0.002832 bow_loss 1.022244 
0.50 elbo_t 1.811549 rc_loss 1.127270 kl_loss 0.002601 bow_loss 0.681678 
0.40 elbo_t 3.156941 rc_loss 1.120147 kl_loss 0.002996 bow_loss 2.033798 
0.40 elbo_t 2.820888 rc_loss 1.117804 kl_loss 0.002948 bow_loss 1.700136 
0.60 elbo_t 2.150337 rc_loss 1.124571 kl_loss 0.002752 bow_loss 1.023014 
0.60 elbo_t 1.816657 rc_loss 1.131781 kl_loss 0.002528 bow_loss 0.682349 
0.50 elbo_t 3.170240 rc_loss 1.125818 kl_loss 0.003047 bow_loss 2.041375 
0.50 elbo_t 2.832124 rc_loss 1.123698 kl_loss 0.002978 bow_loss 1.705448 
0.70 elbo_t 2.154178 rc_loss 1.127337 kl_loss 0.002794 bow_loss 1.024047 
0.70 elbo_t 1.820633 rc_loss 1.134802 kl_loss 0.002584 bow_loss 0.683247 
0.60 elbo_t 3.176298 rc_loss 1.130145 kl_loss 0.002930 bow_loss 2.043222 
0.60 elbo_t 2.838334 rc_loss 1.128342 kl_loss 0.002861 bow_loss 1.707131 
0.80 elbo_t 2.150645 rc_loss 1.123237 kl_loss 0.002670 bow_loss 1.024737 
0.80 elbo_t 1.816536 rc_loss 1.130440 kl_loss 0.002495 bow_loss 0.683601 
0.70 elbo_t 3.181497 rc_loss 1.132992 kl_loss 0.002962 bow_loss 2.045543 
0.70 elbo_t 2.842990 rc_loss 1.131130 kl_loss 0.002884 bow_loss 1.708976 
0.90 elbo_t 2.147685 rc_loss 1.120474 kl_loss 0.002729 bow_loss 1.024482 
0.90 elbo_t 1.813858 rc_loss 1.127923 kl_loss 0.002541 bow_loss 0.683393 
0.80 elbo_t 3.179142 rc_loss 1.129023 kl_loss 0.002843 bow_loss 2.047276 
0.80 elbo_t 2.839548 rc_loss 1.127024 kl_loss 0.002761 bow_loss 1.709763 
1.00 elbo_t 2.144305 rc_loss 1.116924 kl_loss 0.002699 bow_loss 1.024681 
Epoch Done elbo_t 2.144305 rc_loss 1.116924 kl_loss 0.002699 bow_loss 1.024681 step time 15.0434
Best valid loss before this validation: 2.229492
1.00 elbo_t 1.810486 rc_loss 1.124378 kl_loss 0.002518 bow_loss 0.683589 
Epoch Done elbo_t 1.810486 rc_loss 1.124378 kl_loss 0.002518 bow_loss 0.683589 step time 15.0399
Best valid loss before this validation: 1.890069
0.90 elbo_t 3.176006 rc_loss 1.126264 kl_loss 0.002884 bow_loss 2.046857 
0.90 elbo_t 2.836161 rc_loss 1.124262 kl_loss 0.002820 bow_loss 1.709079 
1.00 elbo_t 3.172567 rc_loss 1.122517 kl_loss 0.002871 bow_loss 2.047179 
Epoch Done elbo_t 3.172567 rc_loss 1.122517 kl_loss 0.002871 bow_loss 2.047179 step time 15.2422
Best valid loss before this validation: 3.263586
1.00 elbo_t 2.832514 rc_loss 1.120375 kl_loss 0.002770 bow_loss 1.709370 
Epoch Done elbo_t 2.832514 rc_loss 1.120375 kl_loss 0.002770 bow_loss 1.709370 step time 15.2891
Best valid loss before this validation: 2.919035
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.208436 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.868606 
Get a smaller valid loss, update the best valid loss
Saving the model
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 22
Learning rate 0.001000
>> Epoch 22
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.117771 rc_loss 1.092126 kl_loss 0.002248 bow_loss 1.023398 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.784296 rc_loss 1.099895 kl_loss 0.002379 bow_loss 0.682023 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.242583 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 22
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.898524 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 22
Learning rate 0.001000
0.20 elbo_t 2.107885 rc_loss 1.081590 kl_loss 0.002521 bow_loss 1.023774 
0.20 elbo_t 1.774753 rc_loss 1.089485 kl_loss 0.002517 bow_loss 0.682751 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.146193 rc_loss 1.097640 kl_loss 0.002705 bow_loss 2.045848 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.800612 rc_loss 1.094225 kl_loss 0.002580 bow_loss 1.703807 
0.30 elbo_t 1.774785 rc_loss 1.090906 kl_loss 0.002700 bow_loss 0.681179 
0.30 elbo_t 2.105233 rc_loss 1.082192 kl_loss 0.002731 bow_loss 1.020309 
0.20 elbo_t 3.136679 rc_loss 1.087656 kl_loss 0.002745 bow_loss 2.046278 
0.20 elbo_t 2.793739 rc_loss 1.084654 kl_loss 0.002912 bow_loss 1.706174 
0.40 elbo_t 1.781520 rc_loss 1.096739 kl_loss 0.002639 bow_loss 0.682142 
0.40 elbo_t 2.112725 rc_loss 1.087858 kl_loss 0.002598 bow_loss 1.022269 
0.30 elbo_t 3.130257 rc_loss 1.088238 kl_loss 0.003022 bow_loss 2.038997 
0.30 elbo_t 2.790428 rc_loss 1.085629 kl_loss 0.002928 bow_loss 1.701871 
0.50 elbo_t 1.777480 rc_loss 1.092330 kl_loss 0.002577 bow_loss 0.682572 
0.50 elbo_t 2.109793 rc_loss 1.083935 kl_loss 0.002557 bow_loss 1.023302 
0.40 elbo_t 3.139048 rc_loss 1.093463 kl_loss 0.002962 bow_loss 2.042623 
0.40 elbo_t 2.798753 rc_loss 1.091182 kl_loss 0.002814 bow_loss 1.704758 
0.60 elbo_t 1.782372 rc_loss 1.097255 kl_loss 0.002641 bow_loss 0.682477 
0.60 elbo_t 2.114623 rc_loss 1.088655 kl_loss 0.002626 bow_loss 1.023342 
0.50 elbo_t 3.137810 rc_loss 1.090413 kl_loss 0.002942 bow_loss 2.044454 
0.50 elbo_t 2.796822 rc_loss 1.087929 kl_loss 0.002818 bow_loss 1.706076 
0.70 elbo_t 1.786090 rc_loss 1.100561 kl_loss 0.002588 bow_loss 0.682941 
0.70 elbo_t 2.118176 rc_loss 1.091459 kl_loss 0.002599 bow_loss 1.024118 
0.60 elbo_t 3.142975 rc_loss 1.095549 kl_loss 0.003050 bow_loss 2.044376 
0.60 elbo_t 2.802071 rc_loss 1.093126 kl_loss 0.002862 bow_loss 1.706083 
0.80 elbo_t 1.776926 rc_loss 1.092691 kl_loss 0.002599 bow_loss 0.681636 
0.80 elbo_t 2.108471 rc_loss 1.083715 kl_loss 0.002640 bow_loss 1.022116 
0.70 elbo_t 3.147043 rc_loss 1.098142 kl_loss 0.002983 bow_loss 2.045918 
0.70 elbo_t 2.806215 rc_loss 1.095865 kl_loss 0.002792 bow_loss 1.707559 
0.90 elbo_t 2.111680 rc_loss 1.086951 kl_loss 0.002676 bow_loss 1.022053 
0.90 elbo_t 1.780136 rc_loss 1.095923 kl_loss 0.002570 bow_loss 0.681643 
0.80 elbo_t 3.135194 rc_loss 1.090158 kl_loss 0.003080 bow_loss 2.041957 
0.80 elbo_t 2.795067 rc_loss 1.088073 kl_loss 0.002877 bow_loss 1.704117 
1.00 elbo_t 2.115185 rc_loss 1.089147 kl_loss 0.002691 bow_loss 1.023347 
Epoch Done elbo_t 2.115185 rc_loss 1.089147 kl_loss 0.002691 bow_loss 1.023347 step time 15.3737
Best valid loss before this validation: 2.208436
1.00 elbo_t 1.783026 rc_loss 1.098019 kl_loss 0.002596 bow_loss 0.682411 
Epoch Done elbo_t 1.783026 rc_loss 1.098019 kl_loss 0.002596 bow_loss 0.682411 step time 15.3981
Best valid loss before this validation: 1.868606
0.90 elbo_t 2.798394 rc_loss 1.091354 kl_loss 0.002923 bow_loss 1.704118 
0.90 elbo_t 3.138468 rc_loss 1.093235 kl_loss 0.003173 bow_loss 2.042060 
1.00 elbo_t 3.143227 rc_loss 1.095718 kl_loss 0.003145 bow_loss 2.044365 
Epoch Done elbo_t 3.143227 rc_loss 1.095718 kl_loss 0.003145 bow_loss 2.044365 step time 15.3415
Best valid loss before this validation: 3.242583
1.00 elbo_t 2.803540 rc_loss 1.094114 kl_loss 0.002914 bow_loss 1.706512 
Epoch Done elbo_t 2.803540 rc_loss 1.094114 kl_loss 0.002914 bow_loss 1.706512 step time 15.2393
Best valid loss before this validation: 2.898524
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.186686 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 23
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.849185 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 23
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.128704 rc_loss 1.105155 kl_loss 0.002421 bow_loss 1.021128 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.798612 rc_loss 1.114200 kl_loss 0.002212 bow_loss 0.682200 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.215389 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 23
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.886991 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 23
Learning rate 0.001000
0.20 elbo_t 2.128402 rc_loss 1.101089 kl_loss 0.003074 bow_loss 1.024239 
0.20 elbo_t 1.797510 rc_loss 1.110784 kl_loss 0.002592 bow_loss 0.684135 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.152845 rc_loss 1.108590 kl_loss 0.003701 bow_loss 2.040555 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.834306 rc_loss 1.111313 kl_loss 0.002997 bow_loss 1.719996 
0.30 elbo_t 2.128429 rc_loss 1.099391 kl_loss 0.002826 bow_loss 1.026212 
0.30 elbo_t 1.797370 rc_loss 1.109495 kl_loss 0.002487 bow_loss 0.685388 
0.20 elbo_t 3.155696 rc_loss 1.106211 kl_loss 0.004095 bow_loss 2.045391 
0.20 elbo_t 2.828815 rc_loss 1.107246 kl_loss 0.003721 bow_loss 1.717847 
0.40 elbo_t 2.124125 rc_loss 1.095792 kl_loss 0.002907 bow_loss 1.025425 
0.40 elbo_t 1.792535 rc_loss 1.105517 kl_loss 0.002679 bow_loss 0.684339 
0.30 elbo_t 3.158433 rc_loss 1.105914 kl_loss 0.003641 bow_loss 2.048878 
0.30 elbo_t 2.828745 rc_loss 1.106496 kl_loss 0.003416 bow_loss 1.718832 
0.50 elbo_t 2.112882 rc_loss 1.085091 kl_loss 0.003020 bow_loss 1.024770 
0.50 elbo_t 1.781200 rc_loss 1.094683 kl_loss 0.002765 bow_loss 0.683753 
0.40 elbo_t 3.152543 rc_loss 1.101877 kl_loss 0.003833 bow_loss 2.046833 
0.40 elbo_t 2.821926 rc_loss 1.102076 kl_loss 0.003532 bow_loss 1.716318 
0.60 elbo_t 2.097020 rc_loss 1.072558 kl_loss 0.003007 bow_loss 1.021455 
0.60 elbo_t 1.765901 rc_loss 1.081588 kl_loss 0.002796 bow_loss 0.681516 
0.50 elbo_t 3.140950 rc_loss 1.091388 kl_loss 0.003993 bow_loss 2.045570 
0.50 elbo_t 2.811547 rc_loss 1.091579 kl_loss 0.003754 bow_loss 1.716213 
0.70 elbo_t 2.092574 rc_loss 1.069671 kl_loss 0.003059 bow_loss 1.019843 
0.70 elbo_t 1.761774 rc_loss 1.078496 kl_loss 0.002885 bow_loss 0.680392 
0.60 elbo_t 3.121416 rc_loss 1.078609 kl_loss 0.003940 bow_loss 2.038867 
0.60 elbo_t 2.792037 rc_loss 1.078882 kl_loss 0.003714 bow_loss 1.709441 
0.80 elbo_t 2.088230 rc_loss 1.065439 kl_loss 0.003091 bow_loss 1.019699 
0.80 elbo_t 1.757227 rc_loss 1.073882 kl_loss 0.002930 bow_loss 0.680415 
0.70 elbo_t 3.115164 rc_loss 1.075755 kl_loss 0.004052 bow_loss 2.035357 
0.70 elbo_t 2.785638 rc_loss 1.075949 kl_loss 0.003728 bow_loss 1.705962 
0.90 elbo_t 2.087327 rc_loss 1.064566 kl_loss 0.003187 bow_loss 1.019574 
0.90 elbo_t 1.756324 rc_loss 1.073021 kl_loss 0.003004 bow_loss 0.680300 
0.80 elbo_t 3.110714 rc_loss 1.071405 kl_loss 0.003995 bow_loss 2.035315 
0.80 elbo_t 2.780907 rc_loss 1.071441 kl_loss 0.003744 bow_loss 1.705723 
1.00 elbo_t 2.090154 rc_loss 1.067613 kl_loss 0.003197 bow_loss 1.019344 
Epoch Done elbo_t 2.090154 rc_loss 1.067613 kl_loss 0.003197 bow_loss 1.019344 step time 15.1202
Best valid loss before this validation: 2.186686
1.00 elbo_t 1.759245 rc_loss 1.076007 kl_loss 0.003048 bow_loss 0.680190 
Epoch Done elbo_t 1.759245 rc_loss 1.076007 kl_loss 0.003048 bow_loss 0.680190 step time 15.0919
Best valid loss before this validation: 1.849185
0.90 elbo_t 3.110006 rc_loss 1.070794 kl_loss 0.004109 bow_loss 2.035102 
0.90 elbo_t 2.779639 rc_loss 1.070487 kl_loss 0.003808 bow_loss 1.705343 
1.00 elbo_t 3.112542 rc_loss 1.073514 kl_loss 0.004252 bow_loss 2.034776 
Epoch Done elbo_t 3.112542 rc_loss 1.073514 kl_loss 0.004252 bow_loss 2.034776 step time 15.2128
Best valid loss before this validation: 3.215389
1.00 elbo_t 2.781919 rc_loss 1.073171 kl_loss 0.003873 bow_loss 1.704875 
Epoch Done elbo_t 2.781919 rc_loss 1.073171 kl_loss 0.003873 bow_loss 1.704875 step time 15.2096
Best valid loss before this validation: 2.886991
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.167427 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 24
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.829679 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 24
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.105557 rc_loss 1.074950 kl_loss 0.003157 bow_loss 1.027451 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.772381 rc_loss 1.083344 kl_loss 0.003490 bow_loss 0.685547 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.189388 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 24
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.853261 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 24
Learning rate 0.001000
0.20 elbo_t 2.077928 rc_loss 1.051786 kl_loss 0.003048 bow_loss 1.023093 
0.20 elbo_t 1.746015 rc_loss 1.058788 kl_loss 0.003186 bow_loss 0.684041 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.139004 rc_loss 1.084921 kl_loss 0.002506 bow_loss 2.051576 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.801726 rc_loss 1.083271 kl_loss 0.003708 bow_loss 1.714747 
0.30 elbo_t 2.066026 rc_loss 1.042351 kl_loss 0.003224 bow_loss 1.020451 
0.30 elbo_t 1.735163 rc_loss 1.049242 kl_loss 0.003355 bow_loss 0.682565 
0.20 elbo_t 3.106299 rc_loss 1.059546 kl_loss 0.004498 bow_loss 2.042255 
0.20 elbo_t 2.769988 rc_loss 1.058213 kl_loss 0.003892 bow_loss 1.707884 
0.40 elbo_t 1.731279 rc_loss 1.048231 kl_loss 0.003474 bow_loss 0.679574 
0.40 elbo_t 2.060897 rc_loss 1.041358 kl_loss 0.003422 bow_loss 1.016117 
0.30 elbo_t 3.090221 rc_loss 1.049413 kl_loss 0.004480 bow_loss 2.036329 
0.30 elbo_t 2.755612 rc_loss 1.047920 kl_loss 0.003968 bow_loss 1.703724 
0.50 elbo_t 2.068176 rc_loss 1.048930 kl_loss 0.003393 bow_loss 1.015854 
0.50 elbo_t 1.738672 rc_loss 1.056014 kl_loss 0.003361 bow_loss 0.679298 
0.40 elbo_t 3.081627 rc_loss 1.048651 kl_loss 0.004854 bow_loss 2.028122 
0.40 elbo_t 2.747694 rc_loss 1.046924 kl_loss 0.004350 bow_loss 1.696419 
0.60 elbo_t 1.740957 rc_loss 1.057646 kl_loss 0.003382 bow_loss 0.679928 
0.60 elbo_t 2.070122 rc_loss 1.050393 kl_loss 0.003436 bow_loss 1.016293 
0.50 elbo_t 3.088553 rc_loss 1.055742 kl_loss 0.004833 bow_loss 2.027979 
0.50 elbo_t 2.754555 rc_loss 1.054288 kl_loss 0.004269 bow_loss 1.695998 
0.70 elbo_t 1.738654 rc_loss 1.055648 kl_loss 0.003291 bow_loss 0.679716 
0.70 elbo_t 2.067772 rc_loss 1.048237 kl_loss 0.003395 bow_loss 1.016140 
0.60 elbo_t 3.089905 rc_loss 1.056687 kl_loss 0.004916 bow_loss 2.028302 
0.60 elbo_t 2.756443 rc_loss 1.055323 kl_loss 0.004305 bow_loss 1.696815 
0.80 elbo_t 1.742475 rc_loss 1.059494 kl_loss 0.003290 bow_loss 0.679691 
0.80 elbo_t 2.071432 rc_loss 1.051740 kl_loss 0.003525 bow_loss 1.016166 
0.70 elbo_t 3.088096 rc_loss 1.054559 kl_loss 0.004763 bow_loss 2.028774 
0.70 elbo_t 2.753425 rc_loss 1.053111 kl_loss 0.004315 bow_loss 1.695999 
0.90 elbo_t 1.733735 rc_loss 1.052100 kl_loss 0.003227 bow_loss 0.678409 
0.90 elbo_t 2.062408 rc_loss 1.044737 kl_loss 0.003497 bow_loss 1.014174 
0.80 elbo_t 3.092177 rc_loss 1.057832 kl_loss 0.005058 bow_loss 2.029286 
0.80 elbo_t 2.756691 rc_loss 1.056271 kl_loss 0.004463 bow_loss 1.695957 
1.00 elbo_t 1.736382 rc_loss 1.054140 kl_loss 0.003186 bow_loss 0.679056 
Epoch Done elbo_t 1.736382 rc_loss 1.054140 kl_loss 0.003186 bow_loss 0.679056 step time 15.0946
Best valid loss before this validation: 1.829679
1.00 elbo_t 2.065111 rc_loss 1.046547 kl_loss 0.003534 bow_loss 1.015030 
Epoch Done elbo_t 2.065111 rc_loss 1.046547 kl_loss 0.003534 bow_loss 1.015030 step time 15.2427
Best valid loss before this validation: 2.167427
0.90 elbo_t 3.080719 rc_loss 1.050315 kl_loss 0.005198 bow_loss 2.025205 
0.90 elbo_t 2.746318 rc_loss 1.049102 kl_loss 0.004613 bow_loss 1.692603 
1.00 elbo_t 3.084696 rc_loss 1.052378 kl_loss 0.005414 bow_loss 2.026903 
Epoch Done elbo_t 3.084696 rc_loss 1.052378 kl_loss 0.005414 bow_loss 2.026903 step time 15.2206
Best valid loss before this validation: 3.189388
1.00 elbo_t 2.749765 rc_loss 1.051212 kl_loss 0.004795 bow_loss 1.693759 
Epoch Done elbo_t 2.749765 rc_loss 1.051212 kl_loss 0.004795 bow_loss 1.693759 step time 15.1570
Best valid loss before this validation: 2.853261
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.813541 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 25
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.148855 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 25
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.706537 rc_loss 1.026316 kl_loss 0.003045 bow_loss 0.677176 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.035831 rc_loss 1.018642 kl_loss 0.003610 bow_loss 1.013579 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.172498 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 25
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.828270 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 25
Learning rate 0.001000
0.20 elbo_t 1.720759 rc_loss 1.040582 kl_loss 0.003162 bow_loss 0.677016 
0.20 elbo_t 2.047961 rc_loss 1.031804 kl_loss 0.003741 bow_loss 1.012416 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.049799 rc_loss 1.024549 kl_loss 0.005919 bow_loss 2.019331 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.710709 rc_loss 1.021209 kl_loss 0.004166 bow_loss 1.685333 
0.30 elbo_t 1.712798 rc_loss 1.035157 kl_loss 0.003252 bow_loss 0.674389 
0.30 elbo_t 2.039271 rc_loss 1.026811 kl_loss 0.004014 bow_loss 1.008446 
0.20 elbo_t 3.063582 rc_loss 1.038759 kl_loss 0.006417 bow_loss 2.018406 
0.20 elbo_t 2.727987 rc_loss 1.035771 kl_loss 0.005669 bow_loss 1.686548 
0.40 elbo_t 1.697301 rc_loss 1.021455 kl_loss 0.003180 bow_loss 0.672667 
0.40 elbo_t 2.021921 rc_loss 1.013330 kl_loss 0.003760 bow_loss 1.004831 
0.30 elbo_t 3.048876 rc_loss 1.032573 kl_loss 0.005581 bow_loss 2.010721 
0.30 elbo_t 2.715538 rc_loss 1.030638 kl_loss 0.005457 bow_loss 1.679443 
0.50 elbo_t 1.706802 rc_loss 1.029943 kl_loss 0.003174 bow_loss 0.673685 
0.50 elbo_t 2.031657 rc_loss 1.022385 kl_loss 0.003830 bow_loss 1.005442 
0.40 elbo_t 3.028607 rc_loss 1.019005 kl_loss 0.005882 bow_loss 2.003720 
0.40 elbo_t 2.696588 rc_loss 1.017457 kl_loss 0.005381 bow_loss 1.673750 
0.60 elbo_t 1.713448 rc_loss 1.034705 kl_loss 0.003064 bow_loss 0.675678 
0.60 elbo_t 2.039404 rc_loss 1.027114 kl_loss 0.003798 bow_loss 1.008492 
0.50 elbo_t 3.039634 rc_loss 1.027349 kl_loss 0.005941 bow_loss 2.006344 
0.50 elbo_t 2.707948 rc_loss 1.026452 kl_loss 0.005727 bow_loss 1.675768 
0.70 elbo_t 1.709568 rc_loss 1.030827 kl_loss 0.002838 bow_loss 0.675903 
0.70 elbo_t 2.035331 rc_loss 1.023168 kl_loss 0.003510 bow_loss 1.008653 
0.60 elbo_t 3.050870 rc_loss 1.032725 kl_loss 0.005627 bow_loss 2.012518 
0.60 elbo_t 2.717665 rc_loss 1.031410 kl_loss 0.005401 bow_loss 1.680854 
0.80 elbo_t 1.713307 rc_loss 1.033925 kl_loss 0.002866 bow_loss 0.676515 
0.80 elbo_t 2.039211 rc_loss 1.025952 kl_loss 0.003642 bow_loss 1.009616 
0.70 elbo_t 3.047279 rc_loss 1.028656 kl_loss 0.005584 bow_loss 2.013039 
0.70 elbo_t 2.713981 rc_loss 1.027255 kl_loss 0.005292 bow_loss 1.681434 
0.90 elbo_t 1.710749 rc_loss 1.031021 kl_loss 0.002928 bow_loss 0.676800 
0.90 elbo_t 2.037369 rc_loss 1.023760 kl_loss 0.003610 bow_loss 1.009999 
0.80 elbo_t 3.052381 rc_loss 1.031927 kl_loss 0.005512 bow_loss 2.014941 
0.80 elbo_t 2.719122 rc_loss 1.030572 kl_loss 0.005461 bow_loss 1.683089 
1.00 elbo_t 2.040416 rc_loss 1.026892 kl_loss 0.003653 bow_loss 1.009870 
Epoch Done elbo_t 2.040416 rc_loss 1.026892 kl_loss 0.003653 bow_loss 1.009870 step time 14.9239
Best valid loss before this validation: 2.148855
1.00 elbo_t 1.713881 rc_loss 1.034240 kl_loss 0.002954 bow_loss 0.676687 
Epoch Done elbo_t 1.713881 rc_loss 1.034240 kl_loss 0.002954 bow_loss 0.676687 step time 15.0321
Best valid loss before this validation: 1.813541
0.90 elbo_t 3.050719 rc_loss 1.029748 kl_loss 0.005380 bow_loss 2.015592 
0.90 elbo_t 2.717244 rc_loss 1.028374 kl_loss 0.005240 bow_loss 1.683630 
1.00 elbo_t 3.053902 rc_loss 1.032975 kl_loss 0.005401 bow_loss 2.015525 
Epoch Done elbo_t 3.053902 rc_loss 1.032975 kl_loss 0.005401 bow_loss 2.015525 step time 15.2557
Best valid loss before this validation: 3.172498
1.00 elbo_t 2.720491 rc_loss 1.031634 kl_loss 0.005214 bow_loss 1.683644 
Epoch Done elbo_t 2.720491 rc_loss 1.031634 kl_loss 0.005214 bow_loss 1.683644 step time 15.2837
Best valid loss before this validation: 2.828270
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.128793 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 26
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.798635 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 26
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.015565 rc_loss 1.002504 kl_loss 0.005306 bow_loss 1.007755 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.687607 rc_loss 1.009191 kl_loss 0.003886 bow_loss 0.674530 
0.20 elbo_t 2.032875 rc_loss 1.022215 kl_loss 0.004164 bow_loss 1.006496 
0.20 elbo_t 1.707334 rc_loss 1.028839 kl_loss 0.003718 bow_loss 0.674776 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.145421 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 26
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.809918 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 26
Learning rate 0.001000
0.30 elbo_t 2.004390 rc_loss 1.000144 kl_loss 0.003865 bow_loss 1.000381 
0.30 elbo_t 1.680518 rc_loss 1.005817 kl_loss 0.003401 bow_loss 0.671300 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.020036 rc_loss 1.006115 kl_loss 0.005347 bow_loss 2.008574 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.692973 rc_loss 1.006362 kl_loss 0.006290 bow_loss 1.680321 
0.40 elbo_t 2.017747 rc_loss 1.009396 kl_loss 0.003834 bow_loss 1.004518 
0.40 elbo_t 1.692824 rc_loss 1.015674 kl_loss 0.003302 bow_loss 0.673847 
0.20 elbo_t 3.039318 rc_loss 1.024412 kl_loss 0.005185 bow_loss 2.009721 
0.20 elbo_t 2.708063 rc_loss 1.023630 kl_loss 0.005411 bow_loss 1.679022 
0.50 elbo_t 2.013411 rc_loss 1.005463 kl_loss 0.004005 bow_loss 1.003943 
0.50 elbo_t 1.688556 rc_loss 1.011810 kl_loss 0.003414 bow_loss 0.673332 
0.30 elbo_t 3.005346 rc_loss 1.002464 kl_loss 0.004905 bow_loss 1.997977 
0.30 elbo_t 2.675772 rc_loss 1.001426 kl_loss 0.005327 bow_loss 1.669020 
0.60 elbo_t 2.009912 rc_loss 1.003870 kl_loss 0.004002 bow_loss 1.002040 
0.60 elbo_t 1.685716 rc_loss 1.010319 kl_loss 0.003336 bow_loss 0.672061 
0.40 elbo_t 3.024312 rc_loss 1.013243 kl_loss 0.004659 bow_loss 2.006410 
0.40 elbo_t 2.692873 rc_loss 1.011834 kl_loss 0.004959 bow_loss 1.676081 
0.70 elbo_t 2.014872 rc_loss 1.007636 kl_loss 0.004012 bow_loss 1.003224 
0.70 elbo_t 1.690278 rc_loss 1.014127 kl_loss 0.003385 bow_loss 0.672765 
0.50 elbo_t 3.020059 rc_loss 1.009862 kl_loss 0.004847 bow_loss 2.005350 
0.50 elbo_t 2.688043 rc_loss 1.007687 kl_loss 0.005161 bow_loss 1.675195 
0.80 elbo_t 2.012913 rc_loss 1.005217 kl_loss 0.004112 bow_loss 1.003584 
0.80 elbo_t 1.687848 rc_loss 1.011391 kl_loss 0.003429 bow_loss 0.673028 
0.60 elbo_t 3.015171 rc_loss 1.008471 kl_loss 0.004767 bow_loss 2.001933 
0.60 elbo_t 2.683335 rc_loss 1.006261 kl_loss 0.004860 bow_loss 1.672214 
0.90 elbo_t 2.016740 rc_loss 1.008854 kl_loss 0.003976 bow_loss 1.003911 
0.90 elbo_t 1.691550 rc_loss 1.015160 kl_loss 0.003279 bow_loss 0.673111 
0.70 elbo_t 3.020796 rc_loss 1.012312 kl_loss 0.004650 bow_loss 2.003834 
0.70 elbo_t 2.688997 rc_loss 1.010331 kl_loss 0.004727 bow_loss 1.673938 
1.00 elbo_t 2.018500 rc_loss 1.010200 kl_loss 0.004155 bow_loss 1.004145 
Epoch Done elbo_t 2.018500 rc_loss 1.010200 kl_loss 0.004155 bow_loss 1.004145 step time 14.9598
Best valid loss before this validation: 2.128793
1.00 elbo_t 1.693385 rc_loss 1.016747 kl_loss 0.003379 bow_loss 0.673259 
Epoch Done elbo_t 1.693385 rc_loss 1.016747 kl_loss 0.003379 bow_loss 0.673259 step time 14.9668
Best valid loss before this validation: 1.798635
0.80 elbo_t 3.019520 rc_loss 1.010187 kl_loss 0.004711 bow_loss 2.004622 
0.80 elbo_t 2.687304 rc_loss 1.007940 kl_loss 0.004776 bow_loss 1.674589 
0.90 elbo_t 3.023416 rc_loss 1.013752 kl_loss 0.004563 bow_loss 2.005101 
0.90 elbo_t 2.691244 rc_loss 1.011513 kl_loss 0.004664 bow_loss 1.675068 
1.00 elbo_t 3.024942 rc_loss 1.014788 kl_loss 0.004689 bow_loss 2.005466 
Epoch Done elbo_t 3.024942 rc_loss 1.014788 kl_loss 0.004689 bow_loss 2.005466 step time 15.2435
Best valid loss before this validation: 3.145421
1.00 elbo_t 2.692892 rc_loss 1.012611 kl_loss 0.004809 bow_loss 1.675473 
Epoch Done elbo_t 2.692892 rc_loss 1.012611 kl_loss 0.004809 bow_loss 1.675473 step time 15.1547
Best valid loss before this validation: 2.809918
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.781083 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.111333 
Get a smaller valid loss, update the best valid loss
Saving the model
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 27
Learning rate 0.001000
>> Epoch 27
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.663964 rc_loss 0.989378 kl_loss 0.003136 bow_loss 0.671450 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.986237 rc_loss 0.981846 kl_loss 0.003824 bow_loss 1.000566 
0.20 elbo_t 1.681795 rc_loss 1.005502 kl_loss 0.003607 bow_loss 0.672686 
0.20 elbo_t 2.007139 rc_loss 0.998690 kl_loss 0.004470 bow_loss 1.003979 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.124401 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 27
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.787045 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 27
Learning rate 0.001000
0.30 elbo_t 1.996506 rc_loss 0.993501 kl_loss 0.004646 bow_loss 0.998359 
0.30 elbo_t 1.672890 rc_loss 1.000044 kl_loss 0.003527 bow_loss 0.669318 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.994880 rc_loss 0.986206 kl_loss 0.002934 bow_loss 2.005739 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.659341 rc_loss 0.983300 kl_loss 0.004126 bow_loss 1.671915 
0.40 elbo_t 2.007197 rc_loss 1.000710 kl_loss 0.004846 bow_loss 1.001641 
0.40 elbo_t 1.682184 rc_loss 1.007228 kl_loss 0.003745 bow_loss 0.671211 
0.20 elbo_t 3.017371 rc_loss 1.004470 kl_loss 0.003992 bow_loss 2.008910 
0.20 elbo_t 2.681527 rc_loss 1.001604 kl_loss 0.004859 bow_loss 1.675064 
0.50 elbo_t 2.011048 rc_loss 1.005102 kl_loss 0.004571 bow_loss 1.001376 
0.50 elbo_t 1.686122 rc_loss 1.011641 kl_loss 0.003459 bow_loss 0.671022 
0.30 elbo_t 3.001349 rc_loss 0.999650 kl_loss 0.004566 bow_loss 1.997133 
0.30 elbo_t 2.668722 rc_loss 0.996716 kl_loss 0.005264 bow_loss 1.666742 
0.60 elbo_t 2.014177 rc_loss 1.008104 kl_loss 0.004685 bow_loss 1.001388 
0.60 elbo_t 1.688920 rc_loss 1.014379 kl_loss 0.003557 bow_loss 0.670984 
0.40 elbo_t 3.015894 rc_loss 1.007432 kl_loss 0.004498 bow_loss 2.003964 
0.40 elbo_t 2.681869 rc_loss 1.004490 kl_loss 0.005269 bow_loss 1.672110 
0.70 elbo_t 2.010234 rc_loss 1.003937 kl_loss 0.004467 bow_loss 1.001830 
0.70 elbo_t 1.684737 rc_loss 1.010244 kl_loss 0.003450 bow_loss 0.671042 
0.50 elbo_t 3.019912 rc_loss 1.011605 kl_loss 0.004541 bow_loss 2.003765 
0.50 elbo_t 2.685768 rc_loss 1.008422 kl_loss 0.005100 bow_loss 1.672246 
0.80 elbo_t 2.005159 rc_loss 0.999083 kl_loss 0.004742 bow_loss 1.001334 
0.80 elbo_t 1.679885 rc_loss 1.005560 kl_loss 0.003588 bow_loss 0.670737 
0.60 elbo_t 3.022148 rc_loss 1.013875 kl_loss 0.004763 bow_loss 2.003510 
0.60 elbo_t 2.688852 rc_loss 1.011179 kl_loss 0.005454 bow_loss 1.672219 
0.90 elbo_t 2.005745 rc_loss 0.999960 kl_loss 0.004715 bow_loss 1.001070 
0.90 elbo_t 1.680775 rc_loss 1.006534 kl_loss 0.003641 bow_loss 0.670599 
0.70 elbo_t 3.018176 rc_loss 1.009624 kl_loss 0.004626 bow_loss 2.003926 
0.70 elbo_t 2.684663 rc_loss 1.006772 kl_loss 0.005349 bow_loss 1.672541 
1.00 elbo_t 1.998108 rc_loss 0.994087 kl_loss 0.004732 bow_loss 0.999289 
Epoch Done elbo_t 1.998108 rc_loss 0.994087 kl_loss 0.004732 bow_loss 0.999289 step time 15.0290
Best valid loss before this validation: 2.111333
1.00 elbo_t 1.673597 rc_loss 1.000417 kl_loss 0.003717 bow_loss 0.669464 
Epoch Done elbo_t 1.673597 rc_loss 1.000417 kl_loss 0.003717 bow_loss 0.669464 step time 15.0928
Best valid loss before this validation: 1.781083
0.80 elbo_t 3.012842 rc_loss 1.004871 kl_loss 0.004957 bow_loss 2.003014 
0.80 elbo_t 2.679779 rc_loss 1.002065 kl_loss 0.005706 bow_loss 1.672008 
0.90 elbo_t 3.012847 rc_loss 1.005476 kl_loss 0.004907 bow_loss 2.002465 
0.90 elbo_t 2.680167 rc_loss 1.002756 kl_loss 0.005652 bow_loss 1.671759 
1.00 elbo_t 3.002948 rc_loss 0.998889 kl_loss 0.004946 bow_loss 1.999113 
Epoch Done elbo_t 3.002948 rc_loss 0.998889 kl_loss 0.004946 bow_loss 1.999113 step time 15.3235
Best valid loss before this validation: 3.124401
1.00 elbo_t 2.670972 rc_loss 0.996392 kl_loss 0.005630 bow_loss 1.668950 
Epoch Done elbo_t 2.670972 rc_loss 0.996392 kl_loss 0.005630 bow_loss 1.668950 step time 15.2577
Best valid loss before this validation: 2.787045
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.095991 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 28
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.766958 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 28
Learning rate 0.001000
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.006234 rc_loss 0.997878 kl_loss 0.003877 bow_loss 1.004480 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.681246 rc_loss 1.005641 kl_loss 0.003241 bow_loss 0.672365 
0.20 elbo_t 1.990549 rc_loss 0.984901 kl_loss 0.003531 bow_loss 1.002117 
0.20 elbo_t 1.664522 rc_loss 0.991504 kl_loss 0.002683 bow_loss 0.670334 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.107074 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 28
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.771778 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 28
Learning rate 0.001000
0.30 elbo_t 1.964730 rc_loss 0.966985 kl_loss 0.003679 bow_loss 0.994066 
0.30 elbo_t 1.641772 rc_loss 0.972736 kl_loss 0.003444 bow_loss 0.665592 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 3.016737 rc_loss 1.003812 kl_loss 0.005566 bow_loss 2.007359 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.684135 rc_loss 1.002786 kl_loss 0.004982 bow_loss 1.676367 
0.40 elbo_t 1.962010 rc_loss 0.966612 kl_loss 0.003607 bow_loss 0.991791 
0.40 elbo_t 1.639177 rc_loss 0.971628 kl_loss 0.003314 bow_loss 0.664235 
0.20 elbo_t 2.995975 rc_loss 0.989768 kl_loss 0.004863 bow_loss 2.001344 
0.20 elbo_t 2.662605 rc_loss 0.987227 kl_loss 0.004543 bow_loss 1.670835 
0.50 elbo_t 1.639142 rc_loss 0.970281 kl_loss 0.003822 bow_loss 0.665039 
0.50 elbo_t 1.961932 rc_loss 0.964638 kl_loss 0.004090 bow_loss 0.993204 
0.30 elbo_t 2.962627 rc_loss 0.970870 kl_loss 0.005000 bow_loss 1.986757 
0.30 elbo_t 2.632849 rc_loss 0.968825 kl_loss 0.004764 bow_loss 1.659260 
0.60 elbo_t 1.637341 rc_loss 0.968086 kl_loss 0.004089 bow_loss 0.665166 
0.60 elbo_t 1.959709 rc_loss 0.962371 kl_loss 0.004094 bow_loss 0.993245 
0.40 elbo_t 2.957457 rc_loss 0.970163 kl_loss 0.004812 bow_loss 1.982482 
0.40 elbo_t 2.628931 rc_loss 0.968163 kl_loss 0.004717 bow_loss 1.656050 
0.70 elbo_t 1.644750 rc_loss 0.974758 kl_loss 0.004374 bow_loss 0.665618 
0.70 elbo_t 1.967718 rc_loss 0.969146 kl_loss 0.004431 bow_loss 0.994141 
0.50 elbo_t 2.960269 rc_loss 0.968834 kl_loss 0.005035 bow_loss 1.986399 
0.50 elbo_t 2.630860 rc_loss 0.966698 kl_loss 0.005242 bow_loss 1.658919 
0.80 elbo_t 1.646618 rc_loss 0.976379 kl_loss 0.004447 bow_loss 0.665793 
0.80 elbo_t 1.969456 rc_loss 0.970623 kl_loss 0.004417 bow_loss 0.994417 
0.60 elbo_t 2.958842 rc_loss 0.966737 kl_loss 0.005058 bow_loss 1.987047 
0.60 elbo_t 2.628758 rc_loss 0.964497 kl_loss 0.005135 bow_loss 1.659127 
0.90 elbo_t 1.651538 rc_loss 0.980215 kl_loss 0.004415 bow_loss 0.666907 
0.90 elbo_t 1.974728 rc_loss 0.974243 kl_loss 0.004402 bow_loss 0.996083 
0.70 elbo_t 2.967091 rc_loss 0.973419 kl_loss 0.005156 bow_loss 1.988516 
0.70 elbo_t 2.637198 rc_loss 0.971258 kl_loss 0.005310 bow_loss 1.660631 
1.00 elbo_t 1.654448 rc_loss 0.983042 kl_loss 0.004543 bow_loss 0.666864 
Epoch Done elbo_t 1.654448 rc_loss 0.983042 kl_loss 0.004543 bow_loss 0.666864 step time 15.0103
Best valid loss before this validation: 1.766958
1.00 elbo_t 1.977337 rc_loss 0.976880 kl_loss 0.004491 bow_loss 0.995966 
Epoch Done elbo_t 1.977337 rc_loss 0.976880 kl_loss 0.004491 bow_loss 0.995966 step time 15.0957
Best valid loss before this validation: 2.095991
0.80 elbo_t 2.969318 rc_loss 0.974859 kl_loss 0.005110 bow_loss 1.989350 
0.80 elbo_t 2.639450 rc_loss 0.972923 kl_loss 0.005292 bow_loss 1.661235 
0.90 elbo_t 2.976565 rc_loss 0.978973 kl_loss 0.004951 bow_loss 1.992642 
0.90 elbo_t 2.645755 rc_loss 0.976812 kl_loss 0.004998 bow_loss 1.663944 
1.00 elbo_t 2.978842 rc_loss 0.981597 kl_loss 0.004856 bow_loss 1.992389 
Epoch Done elbo_t 2.978842 rc_loss 0.981597 kl_loss 0.004856 bow_loss 1.992389 step time 15.1625
Best valid loss before this validation: 3.107074
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.753404 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 29
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.082877 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 29
Learning rate 0.001000
1.00 elbo_t 2.648344 rc_loss 0.979534 kl_loss 0.005032 bow_loss 1.663778 
Epoch Done elbo_t 2.648344 rc_loss 0.979534 kl_loss 0.005032 bow_loss 1.663778 step time 15.2448
Best valid loss before this validation: 2.771778
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.579913 rc_loss 0.921732 kl_loss 0.003806 bow_loss 0.654375 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 1.895561 rc_loss 0.916190 kl_loss 0.004374 bow_loss 0.974998 
0.20 elbo_t 1.599316 rc_loss 0.936066 kl_loss 0.003781 bow_loss 0.659468 
0.20 elbo_t 1.917679 rc_loss 0.929629 kl_loss 0.004277 bow_loss 0.983773 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.090442 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 29
Learning rate 0.001000
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.755646 
Get a smaller valid loss, update the best valid loss
Saving the model
>> Epoch 29
Learning rate 0.001000
0.30 elbo_t 1.604754 rc_loss 0.938788 kl_loss 0.004218 bow_loss 0.661747 
0.30 elbo_t 1.925363 rc_loss 0.933324 kl_loss 0.004538 bow_loss 0.987500 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.876444 rc_loss 0.919346 kl_loss 0.004772 bow_loss 1.952327 
Train begins with 10 batches with 5 left over samples
0.10 elbo_t 2.554513 rc_loss 0.917529 kl_loss 0.004749 bow_loss 1.632235 
0.40 elbo_t 1.620631 rc_loss 0.953493 kl_loss 0.004134 bow_loss 0.663004 
0.40 elbo_t 1.941456 rc_loss 0.947358 kl_loss 0.004282 bow_loss 0.989816 
0.20 elbo_t 2.906722 rc_loss 0.933102 kl_loss 0.004215 bow_loss 1.969404 
0.20 elbo_t 2.580986 rc_loss 0.931339 kl_loss 0.004226 bow_loss 1.645422 
0.50 elbo_t 1.630550 rc_loss 0.961697 kl_loss 0.004309 bow_loss 0.664545 
0.50 elbo_t 1.952446 rc_loss 0.955355 kl_loss 0.004521 bow_loss 0.992570 
0.30 elbo_t 2.919694 rc_loss 0.937191 kl_loss 0.004156 bow_loss 1.978347 
0.30 elbo_t 2.591931 rc_loss 0.936019 kl_loss 0.004620 bow_loss 1.651291 
0.60 elbo_t 1.633823 rc_loss 0.965045 kl_loss 0.004129 bow_loss 0.664650 
0.60 elbo_t 1.955058 rc_loss 0.958278 kl_loss 0.004167 bow_loss 0.992613 
0.40 elbo_t 2.938345 rc_loss 0.951668 kl_loss 0.004297 bow_loss 1.982380 
0.40 elbo_t 2.609785 rc_loss 0.950594 kl_loss 0.004181 bow_loss 1.655010 
0.70 elbo_t 1.633025 rc_loss 0.963804 kl_loss 0.004167 bow_loss 0.665054 
0.70 elbo_t 1.954760 rc_loss 0.957142 kl_loss 0.004244 bow_loss 0.993375 
0.50 elbo_t 2.950959 rc_loss 0.959702 kl_loss 0.004494 bow_loss 1.986763 
0.50 elbo_t 2.621888 rc_loss 0.958681 kl_loss 0.004428 bow_loss 1.658779 
0.80 elbo_t 1.960293 rc_loss 0.961164 kl_loss 0.004224 bow_loss 0.994905 
0.80 elbo_t 1.638235 rc_loss 0.967813 kl_loss 0.004283 bow_loss 0.666139 
0.60 elbo_t 2.952882 rc_loss 0.962234 kl_loss 0.004270 bow_loss 1.986378 
0.60 elbo_t 2.623750 rc_loss 0.961058 kl_loss 0.004086 bow_loss 1.658605 
0.90 elbo_t 1.957739 rc_loss 0.960189 kl_loss 0.004109 bow_loss 0.993441 
0.90 elbo_t 1.636542 rc_loss 0.966997 kl_loss 0.004233 bow_loss 0.665312 
0.70 elbo_t 2.952558 rc_loss 0.960820 kl_loss 0.004376 bow_loss 1.987361 
0.70 elbo_t 2.622893 rc_loss 0.959362 kl_loss 0.003990 bow_loss 1.659540 
1.00 elbo_t 1.960643 rc_loss 0.962936 kl_loss 0.004223 bow_loss 0.993484 
Epoch Done elbo_t 1.960643 rc_loss 0.962936 kl_loss 0.004223 bow_loss 0.993484 step time 15.0551
Best valid loss before this validation: 2.082877
1.00 elbo_t 1.639305 rc_loss 0.969558 kl_loss 0.004273 bow_loss 0.665475 
Epoch Done elbo_t 1.639305 rc_loss 0.969558 kl_loss 0.004273 bow_loss 0.665475 step time 15.1770
Best valid loss before this validation: 1.753404
0.80 elbo_t 2.959602 rc_loss 0.965011 kl_loss 0.004331 bow_loss 1.990260 
0.80 elbo_t 2.630077 rc_loss 0.963516 kl_loss 0.004089 bow_loss 1.662471 
0.90 elbo_t 2.955922 rc_loss 0.964147 kl_loss 0.004256 bow_loss 1.987519 
0.90 elbo_t 2.626695 rc_loss 0.962637 kl_loss 0.004012 bow_loss 1.660046 
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.072063 
Get a smaller valid loss, update the best valid loss
Saving the model
Test begins with 3 batches with 16 left over samples
Valid elbo_t 1.743218 
Get a smaller valid loss, update the best valid loss
Saving the model
Total training time: 96.10
ckpt_dir: run1586918862
ckpt_name: vrnn_29.pt
Namespace(ckpt_dir='run1586918862', ckpt_name='vrnn_29.pt', forward_only=True, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.3,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.jso
              n',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.js
                   on',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 6,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.
                   json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 6
Total training time: 96.29
ckpt_dir: run1586918851
ckpt_name: vrnn_29.pt
Namespace(ckpt_dir='run1586918851', ckpt_name='vrnn_29.pt', forward_only=True, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.2,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.jso
              n',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.js
                   on',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 6,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.
                   json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 6
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918862
Load model from log/linear_vrnn/run1586918862/vrnn_29.pt
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918851
Load model from log/linear_vrnn/run1586918851/vrnn_29.pt
1.00 elbo_t 2.958872 rc_loss 0.966589 kl_loss 0.004254 bow_loss 1.988029 
Epoch Done elbo_t 2.958872 rc_loss 0.966589 kl_loss 0.004254 bow_loss 1.988029 step time 15.1602
Best valid loss before this validation: 3.090442
1.00 elbo_t 2.630112 rc_loss 0.965360 kl_loss 0.004037 bow_loss 1.660715 
Epoch Done elbo_t 2.630112 rc_loss 0.965360 kl_loss 0.004037 bow_loss 1.660715 step time 15.1410
Best valid loss before this validation: 2.755646
Test begins with 3 batches with 16 left over samples
Valid elbo_t 3.076952 
Get a smaller valid loss, update the best valid loss
Saving the model
Total training time: 96.23
ckpt_dir: run1586918893
ckpt_name: vrnn_29.pt
Namespace(ckpt_dir='run1586918893', ckpt_name='vrnn_29.pt', forward_only=True, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.6,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.jso
              n',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.js
                   on',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 7,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.
                   json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 7
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918893
Load model from log/linear_vrnn/run1586918893/vrnn_29.pt
Test begins with 3 batches with 16 left over samples
Valid elbo_t 2.742026 
Get a smaller valid loss, update the best valid loss
Saving the model
Total training time: 96.40
ckpt_dir: run1586918885
ckpt_name: vrnn_29.pt
Namespace(ckpt_dir='run1586918885', ckpt_name='vrnn_29.pt', forward_only=True, resume=False, save_model=True)
instance(params):
  api_dir: 'data/cambridge_data/api_cambridge.txt',
  attention_type: 'concat',
  batch_size: 40,
  bow_loss_weight: 0.5,
  cell_type: 'lstm',
  data_dir: 'data/data.pkl',
  data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/train-sample/train-*.jso
              n',
  data_pre: '/home/liang/Workspace/Corpus/#ubuntu-2004/',
  dropout: 0.2,
  early_stop: True,
  embed_size: 300,
  encoding_cell_size: 400,
  eval_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/dev-sample/dev-*.js
                   on',
  eval_num: 100,
  glove_path: '/home/liang/Workspace/Corpus/glove.840B.300d.txt',
  gpu_idx: 7,
  grad_clip: 5.0,
  grad_noise: 0.0,
  improve_threshold: 0.996,
  init_lr: 0.001,
  init_w: 0.08,
  kl_loss_weight: 100000,
  log_dir: 'log',
  lr_decay: 0.6,
  max_dec_steps: 50,
  max_dialog_len: 9,
  max_enc_steps: 50,
  max_epoch: 30,
  max_utt_len: 40,
  max_vocab_cnt: 10000,
  mode: 'train',
  n_state: 10,
  n_training_steps: 100,
  num_layer: 1,
  op: 'adam',
  patient_increase: 2.0,
  print_after: 10,
  rev_vocab_dir: 'data/cambridge_data/rev_vocab.pkl',
  seed: 233,
  state_cell_size: 10,
  temperature: 0.5,
  test_data_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/test-sample/test-*.
                   json',
  use_cuda: True,
  use_glove: False,
  use_struct_attention: True,
  use_test_batch: False,
  vocab_path: '/home/liang/Workspace/Corpus/#ubuntu-2004/vocab',
  with_BOW: True,
  with_BPR: True,
  with_direct_transition: False,
  with_label_loss: False,
  with_word_weights: False,
  word2vec_path: None,
  word_weights: None
Available GPUs: 8
Using GPU: 7
Max dialog len 8 and min dialog len 2 and avg len 4.113580
Max dialog len 7 and min dialog len 2 and avg len 3.963235
Writing logs to log/linear_vrnn/run1586918885
Load model from log/linear_vrnn/run1586918885/vrnn_29.pt
Train begins with 10 batches with 5 left over samples
transition probability:
[[0.09022556 0.07518797 0.09774436 0.05263158 0.04511278 0.09022556
  0.14285714 0.19548872 0.13533835 0.07518797]
 [0.09090909 0.07575758 0.08333333 0.08333333 0.12121212 0.10606061
  0.12878788 0.06818182 0.13636364 0.10606061]
 [0.12931034 0.11206897 0.0862069  0.10344828 0.10344828 0.07758621
  0.06896552 0.12068966 0.10344828 0.09482759]
 [0.07017544 0.09649123 0.10526316 0.14035088 0.0877193  0.05263158
  0.14912281 0.11403509 0.09649123 0.0877193 ]
 [0.11304348 0.08695652 0.04347826 0.06086957 0.11304348 0.07826087
  0.14782609 0.15652174 0.10434783 0.09565217]
 [0.09322034 0.08474576 0.05932203 0.15254237 0.10169492 0.09322034
  0.11864407 0.09322034 0.10169492 0.10169492]
 [0.0890411  0.13013699 0.13013699 0.04794521 0.09589041 0.07534247
  0.12328767 0.06849315 0.15753425 0.08219178]
 [0.05555556 0.11111111 0.08730159 0.12698413 0.16666667 0.07936508
  0.08730159 0.1031746  0.07142857 0.11111111]
 [0.12403101 0.10852713 0.08527132 0.07751938 0.07751938 0.09302326
  0.14728682 0.06976744 0.13178295 0.08527132]
 [0.16964286 0.08928571 0.08035714 0.08928571 0.08035714 0.16071429
  0.13392857 0.08928571 0.0625     0.04464286]]


Most common sentences in state 0
[('thank you goodbye .', 13), ('thank you , goodbye', 5), ('is there anything else ?', 4), ('thank you , goodbye .', 3), ('i [ value_dontcare ]', 2)]
Most common sentences in state 1
[('thank you , goodbye .', 5), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you goodbye .', 4), ('thank you', 3), ('what is the [ slot_address ] and [ slot_phone ] ?', 3)]
Most common sentences in state 2
[('i [ value_dontcare ] .', 4), ('thank you goodbye .', 3), ('i would like an [ value_pricerange ] restaurant in the [ value_area ] [ slot_area ]', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('thank you . goodbye .', 3)]
Most common sentences in state 3
[('thank you goodbye .', 5), ('thank you . goodbye .', 4), ('i [ value_dontcare ] .', 3), ('thank you , goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Most common sentences in state 4
[('thank you , goodbye .', 5), ('thank you goodbye .', 5), ('i [ value_dontcare ] .', 4), ('how about [ value_food ] ?', 3), ('what is the [ slot_postcode ] ?', 3)]
Most common sentences in state 5
[('thank you , goodbye .', 7), ('thank you goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('what is the [ slot_address ] ?', 3), ('i [ value_dontcare ] .', 2)]
Most common sentences in state 6
[('thank you goodbye .', 17), ('thank you , goodbye .', 10), ('i [ value_dontcare ] .', 6), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye', 3)]
Most common sentences in state 7
[('thank you goodbye .', 10), ('thank you , goodbye .', 8), ('i [ value_dontcare ] .', 8), ('is there anything else ?', 4), ('thank you . goodbye .', 4)]
Most common sentences in state 8
[('thank you goodbye .', 11), ('i [ value_dontcare ] .', 7), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye .', 4), ('thank you . goodbye .', 3)]
Most common sentences in state 9
[('thank you goodbye .', 6), ('thank you , goodbye .', 6), ('what is the [ slot_address ] and [ slot_phone ] ?', 5), ('i [ value_dontcare ] .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Train begins with 10 batches with 5 left over samples
transition probability:
[[0.09160305 0.07633588 0.09923664 0.05343511 0.04580153 0.09160305
  0.14503817 0.19847328 0.1221374  0.07633588]
 [0.09160305 0.07633588 0.09160305 0.08396947 0.1221374  0.10687023
  0.12977099 0.06870229 0.1221374  0.10687023]
 [0.12711864 0.10169492 0.08474576 0.10169492 0.11016949 0.07627119
  0.07627119 0.12711864 0.11016949 0.08474576]
 [0.06896552 0.0862069  0.10344828 0.13793103 0.09482759 0.06034483
  0.15517241 0.11206897 0.09482759 0.0862069 ]
 [0.11304348 0.08695652 0.04347826 0.07826087 0.10434783 0.07826087
  0.14782609 0.15652174 0.09565217 0.09565217]
 [0.09243697 0.08403361 0.05882353 0.1512605  0.10084034 0.09243697
  0.11764706 0.09243697 0.1092437  0.10084034]
 [0.08275862 0.13103448 0.13793103 0.04827586 0.09655172 0.07586207
  0.11034483 0.07586207 0.15862069 0.08275862]
 [0.0546875  0.109375   0.0859375  0.125      0.1640625  0.078125
  0.0859375  0.1015625  0.0859375  0.109375  ]
 [0.12598425 0.11023622 0.07874016 0.07874016 0.07874016 0.09448819
  0.14173228 0.07086614 0.13385827 0.08661417]
 [0.17117117 0.09009009 0.08108108 0.08108108 0.08108108 0.16216216
  0.13513514 0.09009009 0.06306306 0.04504505]]


Most common sentences in state 0
[('thank you goodbye .', 13), ('thank you , goodbye', 5), ('is there anything else ?', 4), ('thank you , goodbye .', 3), ('i [ value_dontcare ]', 2)]
Most common sentences in state 1
[('thank you , goodbye .', 5), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you goodbye .', 4), ('thank you', 3), ('what is the [ slot_address ] and [ slot_phone ] ?', 3)]
Most common sentences in state 2
[('i [ value_dontcare ] .', 4), ('thank you goodbye .', 3), ('i would like an [ value_pricerange ] restaurant in the [ value_area ] [ slot_area ]', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('thank you . goodbye .', 3)]
Most common sentences in state 3
[('thank you goodbye .', 5), ('thank you . goodbye .', 4), ('i [ value_dontcare ] .', 3), ('thank you , goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Most common sentences in state 4
[('thank you , goodbye .', 5), ('thank you goodbye .', 5), ('i [ value_dontcare ] .', 4), ('how about [ value_food ] ?', 3), ('what is the [ slot_postcode ] ?', 3)]
Most common sentences in state 5
[('thank you , goodbye .', 7), ('thank you goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('what is the [ slot_address ] ?', 3), ('i [ value_dontcare ] .', 2)]
Most common sentences in state 6
[('thank you goodbye .', 17), ('thank you , goodbye .', 10), ('i [ value_dontcare ] .', 6), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye', 3)]
Most common sentences in state 7
[('thank you goodbye .', 10), ('thank you , goodbye .', 8), ('i [ value_dontcare ] .', 8), ('is there anything else ?', 4), ('thank you . goodbye .', 4)]
Most common sentences in state 8
[('thank you goodbye .', 11), ('i [ value_dontcare ] .', 7), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye .', 4), ('thank you . goodbye .', 3)]
Most common sentences in state 9
[('thank you goodbye .', 6), ('thank you , goodbye .', 6), ('what is the [ slot_address ] and [ slot_phone ] ?', 5), ('i [ value_dontcare ] .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Train begins with 10 batches with 5 left over samples
transition probability:
[[0.09022556 0.08270677 0.09774436 0.05263158 0.04511278 0.09022556
  0.14285714 0.19548872 0.12781955 0.07518797]
 [0.09090909 0.07575758 0.09090909 0.08333333 0.12121212 0.10606061
  0.12878788 0.06818182 0.12878788 0.10606061]
 [0.13043478 0.10434783 0.08695652 0.10434783 0.11304348 0.07826087
  0.06956522 0.12173913 0.10434783 0.08695652]
 [0.06956522 0.08695652 0.10434783 0.13913043 0.08695652 0.06086957
  0.15652174 0.11304348 0.09565217 0.08695652]
 [0.11206897 0.0862069  0.04310345 0.07758621 0.11206897 0.07758621
  0.14655172 0.15517241 0.09482759 0.09482759]
 [0.10169492 0.08474576 0.05084746 0.15254237 0.10169492 0.08474576
  0.12711864 0.09322034 0.11016949 0.09322034]
 [0.08783784 0.12837838 0.12837838 0.0472973  0.09459459 0.07432432
  0.12162162 0.06756757 0.16216216 0.08783784]
 [0.05555556 0.11111111 0.08730159 0.12698413 0.16666667 0.07936508
  0.08730159 0.1031746  0.07142857 0.11111111]
 [0.125      0.109375   0.0703125  0.078125   0.078125   0.1015625
  0.140625   0.0703125  0.140625   0.0859375 ]
 [0.17272727 0.09090909 0.08181818 0.08181818 0.08181818 0.16363636
  0.13636364 0.09090909 0.06363636 0.03636364]]


Most common sentences in state 0
[('thank you goodbye .', 13), ('thank you , goodbye', 5), ('is there anything else ?', 4), ('thank you , goodbye .', 3), ('i [ value_dontcare ]', 2)]
Most common sentences in state 1
[('thank you , goodbye .', 5), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you goodbye .', 4), ('thank you', 3), ('what is the [ slot_address ] and [ slot_phone ] ?', 3)]
Most common sentences in state 2
[('i [ value_dontcare ] .', 4), ('thank you goodbye .', 3), ('i would like an [ value_pricerange ] restaurant in the [ value_area ] [ slot_area ]', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('thank you . goodbye .', 3)]
Most common sentences in state 3
[('thank you goodbye .', 5), ('thank you . goodbye .', 4), ('i [ value_dontcare ] .', 3), ('thank you , goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Most common sentences in state 4
[('thank you , goodbye .', 5), ('thank you goodbye .', 5), ('i [ value_dontcare ] .', 4), ('how about [ value_food ] ?', 3), ('what is the [ slot_postcode ] ?', 3)]
Most common sentences in state 5
[('thank you , goodbye .', 7), ('thank you goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('what is the [ slot_address ] ?', 3), ('i [ value_dontcare ] .', 2)]
Most common sentences in state 6
[('thank you goodbye .', 17), ('thank you , goodbye .', 10), ('i [ value_dontcare ] .', 6), ('how about [ value_food ] [ slot_food ] ?', 5), ('thank you , goodbye', 3)]
Most common sentences in state 7
[('thank you goodbye .', 10), ('thank you , goodbye .', 8), ('i [ value_dontcare ] .', 8), ('is there anything else ?', 4), ('thank you . goodbye .', 4)]
Most common sentences in state 8
[('thank you goodbye .', 11), ('i [ value_dontcare ] .', 7), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye .', 4), ('thank you . goodbye .', 3)]
Most common sentences in state 9
[('thank you goodbye .', 6), ('thank you , goodbye .', 6), ('what is the [ slot_address ] and [ slot_phone ] ?', 5), ('i [ value_dontcare ] .', 3), ('is there anything else available ?', 2)]
Train begins with 10 batches with 5 left over samples
transition probability:
[[0.09090909 0.07575758 0.09848485 0.0530303  0.04545455 0.09090909
  0.14393939 0.1969697  0.12878788 0.07575758]
 [0.09160305 0.07633588 0.09160305 0.08396947 0.1221374  0.10687023
  0.12977099 0.06870229 0.1221374  0.10687023]
 [0.12820513 0.1025641  0.08547009 0.1025641  0.11111111 0.07692308
  0.06837607 0.12820513 0.11111111 0.08547009]
 [0.06956522 0.08695652 0.10434783 0.13913043 0.08695652 0.06086957
  0.15652174 0.11304348 0.09565217 0.08695652]
 [0.11206897 0.0862069  0.04310345 0.07758621 0.11206897 0.07758621
  0.14655172 0.15517241 0.09482759 0.09482759]
 [0.09243697 0.08403361 0.05882353 0.1512605  0.10084034 0.09243697
  0.11764706 0.09243697 0.1092437  0.10084034]
 [0.08965517 0.13103448 0.13793103 0.04827586 0.09655172 0.07586207
  0.11724138 0.06206897 0.15862069 0.08275862]
 [0.0546875  0.109375   0.0859375  0.125      0.1640625  0.078125
  0.0859375  0.109375   0.078125   0.109375  ]
 [0.12598425 0.11023622 0.07086614 0.07874016 0.07874016 0.09448819
  0.14173228 0.07086614 0.14173228 0.08661417]
 [0.17117117 0.09009009 0.08108108 0.08108108 0.08108108 0.16216216
  0.12612613 0.0990991  0.06306306 0.04504505]]


Most common sentences in state 0
[('thank you goodbye .', 13), ('thank you , goodbye', 5), ('is there anything else ?', 4), ('thank you , goodbye .', 3), ('i [ value_dontcare ]', 2)]
Most common sentences in state 1
[('thank you , goodbye .', 5), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you goodbye .', 4), ('thank you', 3), ('what is the [ slot_address ] and [ slot_phone ] ?', 3)]
Most common sentences in state 2
[('i [ value_dontcare ] .', 4), ('thank you goodbye .', 3), ('i would like an [ value_pricerange ] restaurant in the [ value_area ] [ slot_area ]', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('thank you . goodbye .', 3)]
Most common sentences in state 3
[('thank you goodbye .', 5), ('thank you . goodbye .', 4), ('i [ value_dontcare ] .', 3), ('thank you , goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
Most common sentences in state 4
[('thank you , goodbye .', 5), ('thank you goodbye .', 5), ('i [ value_dontcare ] .', 4), ('how about [ value_food ] ?', 3), ('what is the [ slot_postcode ] ?', 3)]
Most common sentences in state 5
[('thank you , goodbye .', 7), ('thank you goodbye .', 3), ('how about [ value_food ] [ slot_food ] ?', 3), ('what is the [ slot_address ] ?', 3), ('i [ value_dontcare ] .', 2)]
Most common sentences in state 6
[('thank you goodbye .', 17), ('thank you , goodbye .', 10), ('i [ value_dontcare ] .', 6), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye', 3)]
Most common sentences in state 7
[('thank you goodbye .', 10), ('thank you , goodbye .', 8), ('i [ value_dontcare ] .', 8), ('is there anything else ?', 4), ('thank you . goodbye .', 4)]
Most common sentences in state 8
[('thank you goodbye .', 11), ('i [ value_dontcare ] .', 7), ('how about [ value_food ] [ slot_food ] ?', 4), ('thank you , goodbye .', 4), ('thank you . goodbye .', 3)]
Most common sentences in state 9
[('thank you goodbye .', 6), ('thank you , goodbye .', 6), ('what is the [ slot_address ] and [ slot_phone ] ?', 5), ('i [ value_dontcare ] .', 3), ('how about [ value_food ] [ slot_food ] ?', 3)]
